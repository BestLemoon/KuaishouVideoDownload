#!/usr/bin/env python3
"""
GitHub Actions sitemap æ›´æ–°è„šæœ¬
"""
import os
import requests
from datetime import datetime
from supabase import create_client, Client

# ç¯å¢ƒå˜é‡é…ç½®
SUPABASE_URL = os.getenv('SUPABASE_URL')
SUPABASE_SERVICE_ROLE_KEY = os.getenv('SUPABASE_SERVICE_ROLE_KEY')
SITE_URL = os.getenv('NEXT_PUBLIC_WEB_URL', 'https://twitterdown.com')

# åˆå§‹åŒ– Supabase å®¢æˆ·ç«¯
supabase: Client = create_client(SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY)

def get_all_posts():
    """è·å–æ‰€æœ‰å·²å‘å¸ƒçš„æ–‡ç« """
    try:
        result = supabase.table("posts").select("slug, locale, created_at").eq("status", "online").execute()
        return result.data if result.data else []
    except Exception as e:
        print(f"è·å–æ–‡ç« æ•°æ®å¤±è´¥: {e}")
        return []

def read_existing_sitemap():
    """è¯»å–ç°æœ‰çš„sitemapæ–‡ä»¶"""
    sitemap_path = "public/sitemap.xml"
    existing_urls = set()
    
    try:
        with open(sitemap_path, 'r', encoding='utf-8') as f:
            content = f.read()
            import re
            url_matches = re.findall(r'<loc>(.*?)</loc>', content)
            existing_urls = set(url_matches)
            print(f"å‘ç°ç°æœ‰sitemapä¸­æœ‰ {len(existing_urls)} ä¸ªURL")
    except FileNotFoundError:
        print("æœªæ‰¾åˆ°ç°æœ‰sitemapæ–‡ä»¶ï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶")
        content = ""
    except Exception as e:
        print(f"è¯»å–sitemapå¤±è´¥: {e}")
        content = ""
        
    return existing_urls, content

def generate_sitemap(posts):
    """ç”Ÿæˆå®Œæ•´çš„sitemap.xmlå†…å®¹"""
    existing_urls, _ = read_existing_sitemap()
    
    # åŸºç¡€URLåˆ—è¡¨ï¼ˆä¸»è¦é¡µé¢ï¼‰
    base_urls = [
        f"{SITE_URL}/",
        f"{SITE_URL}/zh/",
        f"{SITE_URL}/pricing",
        f"{SITE_URL}/zh/pricing",
        f"{SITE_URL}/privacy-policy",
        f"{SITE_URL}/terms-of-service",
    ]
    
    # ç”Ÿæˆsitemapå¤´éƒ¨
    sitemap_content = '<?xml version="1.0" encoding="UTF-8"?>\n<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">'

    # æ·»åŠ åŸºç¡€é¡µé¢
    for url in base_urls:
        sitemap_content += f'''
  <url>
    <loc>{url}</loc>
    <lastmod>{datetime.now().date().isoformat()}</lastmod>
    <changefreq>daily</changefreq>
    <priority>0.8</priority>
  </url>'''

    # æ·»åŠ æ–‡ç« é¡µé¢
    new_urls_added = 0
    for post in posts:
        slug = post.get('slug')
        locale = post.get('locale')
        created_at = post.get('created_at')
        
        if not slug:
            continue
            
        # æ„å»ºæ–‡ç« URL
        if locale == "en":
            url = f"{SITE_URL}/posts/{slug}"
        else:
            url = f"{SITE_URL}/{locale}/posts/{slug}"
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°URL
        if url not in existing_urls:
            new_urls_added += 1
        
        # ä½¿ç”¨æ–‡ç« çš„åˆ›å»ºæ—¶é—´æˆ–å½“å‰æ—¶é—´
        lastmod = created_at or datetime.now().isoformat()
        if 'T' in lastmod:
            lastmod = lastmod.split('T')[0]  # åªå–æ—¥æœŸéƒ¨åˆ†
        
        sitemap_content += f'''
  <url>
    <loc>{url}</loc>
    <lastmod>{lastmod}</lastmod>
    <changefreq>daily</changefreq>
    <priority>0.7</priority>
  </url>'''

    # ç»“æŸsitemap
    sitemap_content += '\n</urlset>'

    return sitemap_content, new_urls_added

def write_sitemap(content):
    """å†™å…¥sitemapæ–‡ä»¶"""
    try:
        os.makedirs("public", exist_ok=True)
        with open("public/sitemap.xml", 'w', encoding='utf-8') as f:
            f.write(content)
        print("âœ… Sitemapæ–‡ä»¶å†™å…¥æˆåŠŸ")
        return True
    except Exception as e:
        print(f"âŒ Sitemapæ–‡ä»¶å†™å…¥å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ›´æ–°Sitemap...")
    
    # è·å–æ‰€æœ‰æ–‡ç« 
    posts = get_all_posts()
    print(f"è·å–åˆ° {len(posts)} ç¯‡æ–‡ç« ")
    
    if not posts:
        print("âŒ æ²¡æœ‰è·å–åˆ°æ–‡ç« æ•°æ®ï¼Œè·³è¿‡sitemapæ›´æ–°")
        return False
    
    # ç”Ÿæˆsitemapå†…å®¹
    sitemap_content, new_urls_added = generate_sitemap(posts)
    
    # å†™å…¥sitemapæ–‡ä»¶
    if write_sitemap(sitemap_content):
        print(f"âœ… Sitemapæ›´æ–°æˆåŠŸï¼æ·»åŠ äº† {new_urls_added} ä¸ªæ–°URL")
        print(f"SitemapåŒ…å«æ€»è®¡ {len(posts) + 6} ä¸ªURLï¼ˆåŒ…æ‹¬åŸºç¡€é¡µé¢ï¼‰")
        return True
    else:
        print("âŒ Sitemapæ›´æ–°å¤±è´¥")
        return False

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1) 