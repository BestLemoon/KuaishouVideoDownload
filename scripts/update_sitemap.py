#!/usr/bin/env python3
"""
GitHub Actions sitemap æ›´æ–°è„šæœ¬
"""
import os
import requests
from datetime import datetime
from supabase import create_client, Client

# ç¯å¢ƒå˜é‡é…ç½®
SUPABASE_URL = os.getenv('SUPABASE_URL')
SUPABASE_SERVICE_ROLE_KEY = os.getenv('SUPABASE_SERVICE_ROLE_KEY')
SITE_URL = os.getenv('NEXT_PUBLIC_WEB_URL', 'https://kuaishou-video-download.com')

# åˆå§‹åŒ– Supabase å®¢æˆ·ç«¯
supabase: Client = create_client(SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY)

def get_all_posts():
    """è·å–æ‰€æœ‰å·²å‘å¸ƒçš„æ–‡ç« """
    try:
        result = supabase.table("posts").select("slug, locale, created_at").eq("status", "online").execute()
        return result.data if result.data else []
    except Exception as e:  
        print(f"è·å–æ–‡ç« æ•°æ®å¤±è´¥: {e}")
        return []

def read_existing_sitemap():
    """è¯»å–ç°æœ‰çš„sitemapæ–‡ä»¶"""
    sitemap_path = "public/sitemap.xml"
    existing_urls = set()
    
    try:
        with open(sitemap_path, 'r', encoding='utf-8') as f:
            content = f.read()
            import re
            url_matches = re.findall(r'<loc>(.*?)</loc>', content)
            existing_urls = set(url_matches)
            print(f"å‘ç°ç°æœ‰sitemapä¸­æœ‰ {len(existing_urls)} ä¸ªURL")
    except FileNotFoundError:
        print("æœªæ‰¾åˆ°ç°æœ‰sitemapæ–‡ä»¶ï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶")
        content = ""
    except Exception as e:
        print(f"è¯»å–sitemapå¤±è´¥: {e}")
        content = ""
        
    return existing_urls, content

def generate_sitemap(posts):
    """ç”Ÿæˆå®Œæ•´çš„sitemap.xmlå†…å®¹"""
    existing_urls, _ = read_existing_sitemap()
    
    # æ”¯æŒçš„è¯­è¨€åˆ—è¡¨
    languages = ['zh', 'es', 'fr', 'de', 'ja', 'ko', 'ar', 'bn', 'hi', 'id']
    
    # åŸºç¡€URLåˆ—è¡¨ï¼ˆä¸»è¦é¡µé¢ï¼‰
    base_urls = [
        # ä¸»é¡µå’Œè¯­è¨€ç‰ˆæœ¬
        f"{SITE_URL}/",  # è‹±æ–‡ä¸»é¡µï¼ˆé»˜è®¤ï¼‰
    ]
    
    # æ·»åŠ å„è¯­è¨€ä¸»é¡µ
    for lang in languages:
        base_urls.append(f"{SITE_URL}/{lang}")
    
    # æ·»åŠ å…¶ä»–åŸºç¡€é¡µé¢
    base_urls.extend([
        f"{SITE_URL}/privacy-policy",
        f"{SITE_URL}/terms-of-service",
    ])
    
    # æ·»åŠ å„è¯­è¨€çš„postsè·¯ç”±é¡µé¢
    base_urls.append(f"{SITE_URL}/posts")  # è‹±æ–‡postsé¡µé¢
    for lang in languages:
        base_urls.append(f"{SITE_URL}/{lang}/posts")
    
    # ç”Ÿæˆsitemapå¤´éƒ¨
    sitemap_content = '<?xml version="1.0" encoding="UTF-8"?>\n<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">'

    # æ·»åŠ åŸºç¡€é¡µé¢  
    for i, url in enumerate(base_urls):
        # ä¸»é¡µä¼˜å…ˆçº§æœ€é«˜
        if url == f"{SITE_URL}/":
            priority = "1.0"
        # è¯­è¨€ä¸»é¡µæ¬¡ä¹‹
        elif url in [f"{SITE_URL}/{lang}" for lang in languages]:
            priority = "0.9"
        # å…¶ä»–åŸºç¡€é¡µé¢
        else:
            priority = "0.8"
            
        sitemap_content += f'''
  <url>
    <loc>{url}</loc>
    <lastmod>{datetime.now().date().isoformat()}</lastmod>
    <changefreq>daily</changefreq>
    <priority>{priority}</priority>
  </url>'''

    # æ·»åŠ æ–‡ç« é¡µé¢
    new_urls_added = 0
    for post in posts:
        slug = post.get('slug')
        locale = post.get('locale')
        created_at = post.get('created_at')
        
        if not slug:
            continue
            
        # æ„å»ºæ–‡ç« URL - è‹±æ–‡æ˜¯é»˜è®¤è¯­è¨€ï¼Œä¸éœ€è¦/enå‰ç¼€
        if locale == "en":
            url = f"{SITE_URL}/posts/{slug}"
        else:
            url = f"{SITE_URL}/{locale}/posts/{slug}"
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°URL
        if url not in existing_urls:
            new_urls_added += 1
        
        # ä½¿ç”¨æ–‡ç« çš„åˆ›å»ºæ—¶é—´æˆ–å½“å‰æ—¶é—´
        lastmod = created_at or datetime.now().isoformat()
        if 'T' in lastmod:
            lastmod = lastmod.split('T')[0]  # åªå–æ—¥æœŸéƒ¨åˆ†
        
        sitemap_content += f'''
  <url>
    <loc>{url}</loc>
    <lastmod>{lastmod}</lastmod>
    <changefreq>daily</changefreq>
    <priority>0.7</priority>
  </url>'''

    # ç»“æŸsitemap
    sitemap_content += '\n</urlset>'

    return sitemap_content, new_urls_added

def write_sitemap(content):
    """å†™å…¥sitemapæ–‡ä»¶"""
    try:
        os.makedirs("public", exist_ok=True)
        with open("public/sitemap.xml", 'w', encoding='utf-8') as f:
            f.write(content)
        print("âœ… Sitemapæ–‡ä»¶å†™å…¥æˆåŠŸ")
        return True
    except Exception as e:
        print(f"âŒ Sitemapæ–‡ä»¶å†™å…¥å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ›´æ–°Sitemap...")
    
    # è·å–æ‰€æœ‰æ–‡ç« 
    posts = get_all_posts()
    print(f"è·å–åˆ° {len(posts)} ç¯‡æ–‡ç« ")
    
    if not posts:
        print("âŒ æ²¡æœ‰è·å–åˆ°æ–‡ç« æ•°æ®ï¼Œè·³è¿‡sitemapæ›´æ–°")
        return False
    
    # ç”Ÿæˆsitemapå†…å®¹
    sitemap_content, new_urls_added = generate_sitemap(posts)
    
    # å†™å…¥sitemapæ–‡ä»¶
    if write_sitemap(sitemap_content):
        # è®¡ç®—æ€»URLæ•°é‡ï¼šåŸºç¡€é¡µé¢(1ä¸»é¡µ + 7è¯­è¨€é¡µé¢ + 2å…¶ä»–é¡µé¢ + 1è‹±æ–‡posts + 7è¯­è¨€posts) + æ–‡ç« æ•°é‡
        total_base_urls = 1 + 7 + 2 + 1 + 7  # 18ä¸ªåŸºç¡€é¡µé¢
        print(f"âœ… Sitemapæ›´æ–°æˆåŠŸï¼æ·»åŠ äº† {new_urls_added} ä¸ªæ–°URL")
        print(f"SitemapåŒ…å«æ€»è®¡ {len(posts) + total_base_urls} ä¸ªURLï¼ˆåŒ…æ‹¬åŸºç¡€é¡µé¢ï¼‰")
        return True
    else:
        print("âŒ Sitemapæ›´æ–°å¤±è´¥")
        return False

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1) 