#!/usr/bin/env python3
"""
GitHub Actions è‡ªåŠ¨åšå®¢æ–‡ç« ç”Ÿæˆè„šæœ¬ - å…³é”®è¯é©±åŠ¨ç‰ˆæœ¬
"""
import os
import requests
import time
import random
import re
from datetime import datetime
from google.generativeai import configure, GenerativeModel
from supabase import create_client, Client
import uuid
from typing import List, Dict, Any

# ç¯å¢ƒå˜é‡é…ç½®
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
SUPABASE_URL = os.getenv('SUPABASE_URL')
SUPABASE_SERVICE_ROLE_KEY = os.getenv('SUPABASE_SERVICE_ROLE_KEY')
UNSPLASH_ACCESS_KEY = os.getenv('UNSPLASH_ACCESS_KEY')
SITE_URL = os.getenv('NEXT_PUBLIC_WEB_URL', 'https://kuaishou-video-download.com')

# åˆå§‹åŒ–æœåŠ¡
configure(api_key=GEMINI_API_KEY)
supabase: Client = create_client(SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY)

def get_unsplash_image(query="short video"):
    """ä»Unsplashè·å–å›¾ç‰‡ - ä¼˜åŒ–ä¸ºçŸ­è§†é¢‘ç›¸å…³å…³é”®è¯"""
    try:
        if not UNSPLASH_ACCESS_KEY:
            return "https://images.unsplash.com/photo-1611605698335-8b1569810432?w=800&q=80"

        # çŸ­è§†é¢‘ç›¸å…³çš„å…³é”®è¯åˆ—è¡¨
        short_video_keywords = [
            "short video", "mobile video", "social media", "smartphone recording",
            "video content", "digital media", "content creation", "video editing",
            "mobile phone", "social network", "video streaming", "online video",
            "vertical video", "tiktok style", "video maker", "video production"
        ]

        # éšæœºé€‰æ‹©ä¸€ä¸ªçŸ­è§†é¢‘ç›¸å…³å…³é”®è¯ï¼Œå¦‚æœæ²¡æœ‰æä¾›ç‰¹å®šæŸ¥è¯¢
        if query == "short video" or "kuaishou" in query.lower():
            query = random.choice(short_video_keywords)

        headers = {"Authorization": f"Client-ID {UNSPLASH_ACCESS_KEY}"}
        response = requests.get(
            f"https://api.unsplash.com/search/photos?query={query}&per_page=30&orientation=landscape",
            headers=headers,
            timeout=10
        )

        if response.status_code == 200:
            data = response.json()
            if data.get('results'):
                photo = random.choice(data['results'])
                return f"{photo['urls']['regular']}?w=800&q=80"

        return "https://images.unsplash.com/photo-1611605698335-8b1569810432?w=800&q=80"
    except Exception as e:
        print(f"è·å–Unsplashå›¾ç‰‡å¤±è´¥: {e}")
        return "https://images.unsplash.com/photo-1611605698335-8b1569810432?w=800&q=80"

def generate_seed_keywords(language: str, count: int = 8) -> List[str]:
    """ç”Ÿæˆç§å­å…³é”®è¯"""
    model = GenerativeModel("gemini-2.5-flash-preview-05-20")
    
    prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„SEOå…³é”®è¯ç ”ç©¶ä¸“å®¶ï¼Œä¸“æ³¨äºå¿«æ‰‹è§†é¢‘ä¸‹è½½ç›¸å…³çš„å…³é”®è¯ç ”ç©¶ã€‚

## ä»»åŠ¡
è¯·ä¸ºKuaishouVideoDownloadï¼ˆå¿«æ‰‹è§†é¢‘ä¸‹è½½å™¨ï¼‰ç”Ÿæˆ{count}ä¸ªé«˜ä»·å€¼çš„ç§å­å…³é”®è¯ã€‚

## å…³é”®è¯ç±»å‹è¦æ±‚
è¯·ç”Ÿæˆä»¥ä¸‹ç±»å‹çš„å…³é”®è¯ï¼š
1. ğŸ” æœç´¢å‹å…³é”®è¯ï¼ˆç”¨æˆ·ç›´æ¥æœç´¢éœ€æ±‚ï¼‰
2. ğŸ“± è®¾å¤‡ç›¸å…³å…³é”®è¯ï¼ˆiPhone, Android, mobileç­‰ï¼‰
3. ğŸ“Š åŠŸèƒ½å‹å…³é”®è¯ï¼ˆbatch download, HD qualityç­‰ï¼‰
4. ğŸ’¡ è§£å†³æ–¹æ¡ˆå‹å…³é”®è¯ï¼ˆhow to, best wayç­‰ï¼‰
5. ğŸŒ ç«å“å’Œæ¯”è¾ƒå…³é”®è¯ï¼ˆvs, alternativeç­‰ï¼‰

## ç›®æ ‡è¯­è¨€
{language}

## è¾“å‡ºè¦æ±‚
- ç›´æ¥è¾“å‡º{count}ä¸ªå…³é”®è¯
- æ¯è¡Œä¸€ä¸ªå…³é”®è¯
- ä¸åŒ…å«ç¼–å·æˆ–ç¬¦å·
- å…³é”®è¯åº”è¯¥å…·æœ‰æœç´¢ä»·å€¼
- é¿å…è¿‡äºå®½æ³›æˆ–è¿‡äºç»†åˆ†çš„è¯

è¯·å¼€å§‹ç”Ÿæˆï¼š

(å”¯ä¸€æ€§æ ‡è¯†: {int(time.time())})"""

    try:
        result = model.generate_content(prompt)
        if not result.text:
            raise ValueError("AIæœªèƒ½ç”Ÿæˆç§å­å…³é”®è¯")
        
        # è§£æå…³é”®è¯
        keywords = []
        lines = result.text.strip().split('\n')
        for line in lines:
            line = line.strip()
            if line and not line.startswith('#') and not line.startswith('-'):
                # æ¸…ç†å¯èƒ½çš„ç¼–å·å’Œç¬¦å·
                keyword = re.sub(r'^\d+\.?\s*', '', line)
                keyword = re.sub(r'^[â€¢\-\*]\s*', '', keyword)
                keyword = keyword.strip('"').strip("'").strip()
                if keyword and len(keyword) > 2:
                    keywords.append(keyword)
        
        # ç¡®ä¿è¿”å›æŒ‡å®šæ•°é‡
        keywords = keywords[:count]
        print(f"âœ… ç”Ÿæˆäº†{len(keywords)}ä¸ª{language}ç§å­å…³é”®è¯")
        return keywords if keywords else get_default_seed_keywords(language, count)
        
    except Exception as e:
        print(f"âŒ ç§å­å…³é”®è¯ç”Ÿæˆå¤±è´¥: {e}")
        return get_default_seed_keywords(language, count)

def get_default_seed_keywords(language: str, count: int) -> List[str]:
    """è·å–é»˜è®¤ç§å­å…³é”®è¯"""
    if "chinese" in language.lower() or "ä¸­æ–‡" in language:
        default_keywords = [
            "å¿«æ‰‹è§†é¢‘ä¸‹è½½",
            "å¿«æ‰‹è§†é¢‘ä¿å­˜",
            "å¿«æ‰‹çŸ­è§†é¢‘ä¸‹è½½",
            "å¿«æ‰‹ä¸‹è½½å™¨",
            "å¿«æ‰‹è§†é¢‘ä¸‹è½½å·¥å…·",
            "å¿«æ‰‹è§†é¢‘ä¿å­˜",
            "å¿«æ‰‹çŸ­è§†é¢‘",
            "ä¸‹è½½å¿«æ‰‹è§†é¢‘"
        ]
    else:
        default_keywords = [
            "kuaishou video downloader",
            "download kuaishou video",
            "kuaishou video download",
            "kuaishou downloader",
            "save kuaishou video",
            "kuaishou video saver",
            "download from kuaishou",
            "kuaishou media download"
        ]
    
    return default_keywords[:count]

def get_google_suggestions(keyword: str, max_suggestions: int = 8) -> List[str]:
    """ä½¿ç”¨Googleè‡ªåŠ¨å®ŒæˆAPIè·å–å…³é”®è¯å»ºè®®"""
    try:
        url = "http://suggestqueries.google.com/complete/search"
        params = {
            'client': 'firefox',
            'q': keyword
        }
        
        print(f"ğŸ” è·å–'{keyword}'çš„Googleè‡ªåŠ¨å®Œæˆå»ºè®®...")
        
        response = requests.get(url, params=params, timeout=10)
        response.raise_for_status()
        
        suggestions_data = response.json()
        if len(suggestions_data) >= 2 and isinstance(suggestions_data[1], list):
            suggestions = suggestions_data[1][:max_suggestions]
            
            # è¿‡æ»¤å’Œæ¸…ç†å»ºè®®
            filtered_suggestions = []
            for suggestion in suggestions:
                if isinstance(suggestion, str) and suggestion.strip():
                    # ç§»é™¤Unicodeè½¬ä¹‰å­—ç¬¦
                    clean_suggestion = suggestion.encode().decode('unicode_escape')
                    filtered_suggestions.append(clean_suggestion)
            
            print(f"âœ… è·å–åˆ°{len(filtered_suggestions)}ä¸ªè‡ªåŠ¨å®Œæˆå»ºè®®")
            return filtered_suggestions
        else:
            print("âš ï¸ æ²¡æœ‰è·å–åˆ°æœ‰æ•ˆçš„è‡ªåŠ¨å®Œæˆå»ºè®®")
            return []
            
    except Exception as e:
        print(f"âŒ è·å–Googleè‡ªåŠ¨å®Œæˆå»ºè®®å¤±è´¥: {e}")
        return []

def expand_keywords_with_google(seed_keywords: List[str], max_per_keyword: int = 6) -> Dict[str, List[str]]:
    """ä½¿ç”¨Googleè‡ªåŠ¨å®Œæˆæ‰©å±•ç§å­å…³é”®è¯"""
    expanded_keywords = {}
    
    print(f"\nğŸš€ å¼€å§‹æ‰©å±•{len(seed_keywords)}ä¸ªç§å­å…³é”®è¯...")
    
    for i, keyword in enumerate(seed_keywords, 1):
        print(f"\nè¿›åº¦: {i}/{len(seed_keywords)} - å¤„ç†: {keyword}")
        
        suggestions = get_google_suggestions(keyword, max_per_keyword)
        if suggestions:
            expanded_keywords[keyword] = suggestions
        
        # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
        if i < len(seed_keywords):
            time.sleep(1)  # 1ç§’å»¶è¿Ÿ
    
    return expanded_keywords

def generate_categorized_topics_by_keywords_with_count(expanded_keywords: Dict[str, List[str]], language: str, target_count: int) -> Dict[str, List[str]]:
    """æ ¹æ®æ‰©å±•çš„å…³é”®è¯å’Œç›®æ ‡æ•°é‡ï¼ŒæŒ‰åˆ†ç±»ç”Ÿæˆæ–‡ç« é¢˜ç›®"""
    model = GenerativeModel("gemini-2.5-flash-preview-05-20")

    # å°†æ‰€æœ‰å…³é”®è¯åˆå¹¶æˆä¸€ä¸ªåˆ—è¡¨ç”¨äºAIåˆ†æ
    all_keywords = []
    for seed_keyword, suggestions in expanded_keywords.items():
        all_keywords.append(seed_keyword)
        all_keywords.extend(suggestions)

    # å»é‡
    unique_keywords = list(set(all_keywords))
    keywords_text = '\n'.join(f"- {kw}" for kw in unique_keywords[:50])  # é™åˆ¶å…³é”®è¯æ•°é‡

    # æ ¹æ®ç›®æ ‡æ•°é‡åˆ†é…æ–‡ç« ç±»å‹
    if target_count <= 3:
        search_count = target_count
        tutorial_count = 0
        feature_count = 0
    elif target_count <= 5:
        search_count = target_count - 1
        tutorial_count = 1
        feature_count = 0
    elif target_count <= 8:
        search_count = target_count - 2
        tutorial_count = 1
        feature_count = 1
    else:
        search_count = target_count - 3
        tutorial_count = 2
        feature_count = 1

    prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„SEOå†…å®¹ç­–ç•¥å¸ˆï¼Œä¸“æ³¨äºKuaishouVideoDownloadï¼ˆå¿«æ‰‹è§†é¢‘ä¸‹è½½å™¨ï¼‰ç›¸å…³çš„å†…å®¹åˆ›ä½œã€‚

## ä»»åŠ¡
åŸºäºä»¥ä¸‹æ‰©å±•å…³é”®è¯ï¼ŒæŒ‰ç…§æŒ‡å®šç±»åˆ«ç”Ÿæˆæ–‡ç« é¢˜ç›®å»ºè®®ã€‚

## å¯ç”¨å…³é”®è¯ï¼š
{keywords_text}

## æ–‡ç« ç±»åˆ«è¦æ±‚ï¼š

### ğŸ” æœç´¢å‹å…³é”®è¯æ–‡ç« ï¼ˆéœ€è¦{search_count}ç¯‡ï¼‰
- é’ˆå¯¹ç”¨æˆ·æœç´¢æ„å›¾ï¼Œé•¿å°¾å…³é”®è¯ä¸ºä¸»
- å¦‚"how to download Kuaishou video on iPhone"
- è§£å†³å…·ä½“ç”¨æˆ·é—®é¢˜çš„æ–‡ç« 
éœ€è¦ç”Ÿæˆï¼š{search_count}ä¸ªé¢˜ç›®

### ğŸ“˜ æ•™ç¨‹å‹/åˆ—è¡¨å‹æ–‡ç« ï¼ˆéœ€è¦{tutorial_count}ç¯‡ï¼‰
- å¢åŠ åˆ†äº«ç‡ï¼Œé€‚åˆå†…éƒ¨é“¾æ¥
- å¦‚"Top 5 Kuaishou Video Downloaders 2025"
- æ¯”è¾ƒã€æ’è¡Œã€å®Œæ•´æŒ‡å—ç±»å‹
éœ€è¦ç”Ÿæˆï¼š{tutorial_count}ä¸ªé¢˜ç›®

### ğŸŒ åŠŸèƒ½ä»‹ç»æ–‡ç« ï¼ˆéœ€è¦{feature_count}ç¯‡ï¼‰
- ä»‹ç»å¿«æ‰‹è§†é¢‘ä¸‹è½½çš„å„ç§åŠŸèƒ½å’ŒæŠ€å·§
- æå‡ç”¨æˆ·ä½“éªŒå’Œäº§å“è®¤çŸ¥
éœ€è¦ç”Ÿæˆï¼š{feature_count}ä¸ªé¢˜ç›®

## è¯­è¨€è¦æ±‚
{language}

## è¾“å‡ºæ ¼å¼
è¯·ä½¿ç”¨ä»¥ä¸‹æ ¼å¼ï¼š

===SEARCH_KEYWORDS_START===
[{search_count}ä¸ªæœç´¢å‹æ–‡ç« é¢˜ç›®ï¼Œæ¯è¡Œä¸€ä¸ª]
===SEARCH_KEYWORDS_END===

===TUTORIAL_LISTS_START===
[{tutorial_count}ä¸ªæ•™ç¨‹å‹/åˆ—è¡¨å‹æ–‡ç« é¢˜ç›®ï¼Œæ¯è¡Œä¸€ä¸ª]
===TUTORIAL_LISTS_END===

===FEATURE_CONTENT_START===
[{feature_count}ä¸ªåŠŸèƒ½ä»‹ç»æ–‡ç« é¢˜ç›®ï¼Œæ¯è¡Œä¸€ä¸ª]
===FEATURE_CONTENT_END===

è¯·ç¡®ä¿æ‰€æœ‰é¢˜ç›®éƒ½ä¸æä¾›çš„å…³é”®è¯ç›¸å…³ï¼Œå…·æœ‰SEOä»·å€¼ï¼š

(å”¯ä¸€æ€§æ ‡è¯†: {int(time.time())})"""

    try:
        result = model.generate_content(prompt)
        if not result.text:
            raise ValueError("AIæœªèƒ½ç”Ÿæˆåˆ†ç±»æ–‡ç« é¢˜ç›®")

        # è§£æåˆ†ç±»é¢˜ç›®
        categories = {
            'search_keywords': extract_category_topics(result.text, "===SEARCH_KEYWORDS_START===", "===SEARCH_KEYWORDS_END==="),
            'tutorial_lists': extract_category_topics(result.text, "===TUTORIAL_LISTS_START===", "===TUTORIAL_LISTS_END==="),
            'feature_content': extract_category_topics(result.text, "===FEATURE_CONTENT_START===", "===FEATURE_CONTENT_END===")
        }

        print(f"âœ… æˆåŠŸç”Ÿæˆåˆ†ç±»æ–‡ç« é¢˜ç›®:")
        for category, topics in categories.items():
            print(f"   {category}: {len(topics)}ä¸ªé¢˜ç›®")

        return categories

    except Exception as e:
        print(f"âŒ åˆ†ç±»æ–‡ç« é¢˜ç›®ç”Ÿæˆå¤±è´¥: {e}")
        return get_default_category_topics_with_count(language, target_count)

def generate_categorized_topics_by_keywords(expanded_keywords: Dict[str, List[str]], language: str) -> Dict[str, List[str]]:
    """æ ¹æ®æ‰©å±•çš„å…³é”®è¯ï¼ŒæŒ‰åˆ†ç±»ç”Ÿæˆæ–‡ç« é¢˜ç›®"""
    model = GenerativeModel("gemini-2.5-flash-preview-05-20")
    
    # å°†æ‰€æœ‰å…³é”®è¯åˆå¹¶æˆä¸€ä¸ªåˆ—è¡¨ç”¨äºAIåˆ†æ
    all_keywords = []
    for seed_keyword, suggestions in expanded_keywords.items():
        all_keywords.append(seed_keyword)
        all_keywords.extend(suggestions)
    
    # å»é‡
    unique_keywords = list(set(all_keywords))
    keywords_text = '\n'.join(f"- {kw}" for kw in unique_keywords[:50])  # é™åˆ¶å…³é”®è¯æ•°é‡
    
    prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„SEOå†…å®¹ç­–ç•¥å¸ˆï¼Œä¸“æ³¨äºKuaishouVideoDownloadï¼ˆå¿«æ‰‹è§†é¢‘ä¸‹è½½å™¨ï¼‰ç›¸å…³çš„å†…å®¹åˆ›ä½œã€‚

## ä»»åŠ¡
åŸºäºä»¥ä¸‹æ‰©å±•å…³é”®è¯ï¼ŒæŒ‰ç…§æŒ‡å®šç±»åˆ«ç”Ÿæˆæ–‡ç« é¢˜ç›®å»ºè®®ã€‚

## å¯ç”¨å…³é”®è¯ï¼š
{keywords_text}

## æ–‡ç« ç±»åˆ«è¦æ±‚ï¼š

### ğŸ” æœç´¢å‹å…³é”®è¯æ–‡ç« ï¼ˆæ¯æ—¥3ç¯‡ï¼‰
- é’ˆå¯¹ç”¨æˆ·æœç´¢æ„å›¾ï¼Œé•¿å°¾å…³é”®è¯ä¸ºä¸»
- å¦‚"how to download Kuaishou video on iPhone"
- è§£å†³å…·ä½“ç”¨æˆ·é—®é¢˜çš„æ–‡ç« 
éœ€è¦ç”Ÿæˆï¼š3ä¸ªé¢˜ç›®

### ğŸ“˜ æ•™ç¨‹å‹/åˆ—è¡¨å‹æ–‡ç« ï¼ˆæ¯æ—¥1ç¯‡ï¼‰
- å¢åŠ åˆ†äº«ç‡ï¼Œé€‚åˆå†…éƒ¨é“¾æ¥
- å¦‚"Top 5 Kuaishou Video Downloaders 2025"
- æ¯”è¾ƒã€æ’è¡Œã€å®Œæ•´æŒ‡å—ç±»å‹
éœ€è¦ç”Ÿæˆï¼š1ä¸ªé¢˜ç›®

### ğŸŒ åŠŸèƒ½ä»‹ç»æ–‡ç« ï¼ˆæ¯æ—¥1ç¯‡ï¼‰
- ä»‹ç»å¿«æ‰‹è§†é¢‘ä¸‹è½½çš„å„ç§åŠŸèƒ½å’ŒæŠ€å·§
- æå‡ç”¨æˆ·ä½“éªŒå’Œäº§å“è®¤çŸ¥
éœ€è¦ç”Ÿæˆï¼š1ä¸ªé¢˜ç›®

## è¯­è¨€è¦æ±‚
{language}

## è¾“å‡ºæ ¼å¼
è¯·ä½¿ç”¨ä»¥ä¸‹æ ¼å¼ï¼š

===SEARCH_KEYWORDS_START===
[3ä¸ªæœç´¢å‹æ–‡ç« é¢˜ç›®ï¼Œæ¯è¡Œä¸€ä¸ª]
===SEARCH_KEYWORDS_END===

===TUTORIAL_LISTS_START===
[1ä¸ªæ•™ç¨‹å‹/åˆ—è¡¨å‹æ–‡ç« é¢˜ç›®]
===TUTORIAL_LISTS_END===

===FEATURE_CONTENT_START===
[1ä¸ªåŠŸèƒ½ä»‹ç»æ–‡ç« é¢˜ç›®]
===FEATURE_CONTENT_END===

è¯·ç¡®ä¿æ‰€æœ‰é¢˜ç›®éƒ½ä¸æä¾›çš„å…³é”®è¯ç›¸å…³ï¼Œå…·æœ‰SEOä»·å€¼ï¼š

(å”¯ä¸€æ€§æ ‡è¯†: {int(time.time())})"""

    try:
        result = model.generate_content(prompt)
        if not result.text:
            raise ValueError("AIæœªèƒ½ç”Ÿæˆåˆ†ç±»æ–‡ç« é¢˜ç›®")
        
        # è§£æåˆ†ç±»é¢˜ç›®
        categories = {
            'search_keywords': extract_category_topics(result.text, "===SEARCH_KEYWORDS_START===", "===SEARCH_KEYWORDS_END==="),
            'tutorial_lists': extract_category_topics(result.text, "===TUTORIAL_LISTS_START===", "===TUTORIAL_LISTS_END==="),
            'feature_content': extract_category_topics(result.text, "===FEATURE_CONTENT_START===", "===FEATURE_CONTENT_END===")
        }
        
        print(f"âœ… æˆåŠŸç”Ÿæˆåˆ†ç±»æ–‡ç« é¢˜ç›®:")
        for category, topics in categories.items():
            print(f"   {category}: {len(topics)}ä¸ªé¢˜ç›®")
        
        return categories
        
    except Exception as e:
        print(f"âŒ åˆ†ç±»æ–‡ç« é¢˜ç›®ç”Ÿæˆå¤±è´¥: {e}")
        return get_default_category_topics(language)

def extract_category_topics(content: str, start_delimiter: str, end_delimiter: str) -> List[str]:
    """ä»åˆ†éš”ç¬¦ä¸­æå–åˆ†ç±»é¢˜ç›®"""
    try:
        start_idx = content.find(start_delimiter)
        end_idx = content.find(end_delimiter)
        
        if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
            start_idx += len(start_delimiter)
            section_content = content[start_idx:end_idx].strip()
            
            # è§£æé¢˜ç›®
            topics = []
            lines = section_content.split('\n')
            for line in lines:
                line = line.strip()
                if line and not line.startswith('#') and not line.startswith('==='):
                    # æ¸…ç†ç¼–å·å’Œç¬¦å·
                    topic = re.sub(r'^\d+\.?\s*', '', line)
                    topic = re.sub(r'^[â€¢\-\*]\s*', '', topic)
                    topic = topic.strip()
                    if topic:
                        topics.append(topic)
            
            return topics
        
        return []
        
    except Exception:
        return []

def get_default_category_topics_with_count(language: str, target_count: int) -> Dict[str, List[str]]:
    """æ ¹æ®ç›®æ ‡æ•°é‡è·å–é»˜è®¤åˆ†ç±»é¢˜ç›®"""
    # æ ¹æ®è¯­è¨€è·å–åŸºç¡€é¢˜ç›®æ¨¡æ¿
    if "hindi" in language.lower() or "à¤¹à¤¿à¤‚à¤¦à¥€" in language:
        base_topics = {
            'search_keywords': [
                "à¤•à¥à¤†à¤ˆà¤¶à¥Œ à¤µà¥€à¤¡à¤¿à¤¯à¥‹ à¤¡à¤¾à¤‰à¤¨à¤²à¥‹à¤¡ à¤•à¥ˆà¤¸à¥‡ à¤•à¤°à¥‡à¤‚",
                "iPhone à¤ªà¤° à¤•à¥à¤†à¤ˆà¤¶à¥Œ à¤µà¥€à¤¡à¤¿à¤¯à¥‹ à¤¡à¤¾à¤‰à¤¨à¤²à¥‹à¤¡ à¤•à¤°à¤¨à¥‡ à¤•à¤¾ à¤¤à¤°à¥€à¤•à¤¾",
                "à¤¬à¤¿à¤¨à¤¾ à¤µà¥‰à¤Ÿà¤°à¤®à¤¾à¤°à¥à¤• à¤•à¥à¤†à¤ˆà¤¶à¥Œ à¤µà¥€à¤¡à¤¿à¤¯à¥‹ à¤¡à¤¾à¤‰à¤¨à¤²à¥‹à¤¡",
                "à¤•à¥à¤†à¤ˆà¤¶à¥Œ à¤µà¥€à¤¡à¤¿à¤¯à¥‹ à¤¡à¤¾à¤‰à¤¨à¤²à¥‹à¤¡à¤° à¤à¤ª",
                "à¤®à¥à¤«à¥à¤¤ à¤•à¥à¤†à¤ˆà¤¶à¥Œ à¤µà¥€à¤¡à¤¿à¤¯à¥‹ à¤¡à¤¾à¤‰à¤¨à¤²à¥‹à¤¡",
                "Android à¤ªà¤° à¤•à¥à¤†à¤ˆà¤¶à¥Œ à¤µà¥€à¤¡à¤¿à¤¯à¥‹ à¤¸à¥‡à¤µ à¤•à¤°à¥‡à¤‚",
                "à¤•à¥à¤†à¤ˆà¤¶à¥Œ à¤¸à¥‡ HD à¤µà¥€à¤¡à¤¿à¤¯à¥‹ à¤¡à¤¾à¤‰à¤¨à¤²à¥‹à¤¡",
                "à¤•à¥à¤†à¤ˆà¤¶à¥Œ à¤µà¥€à¤¡à¤¿à¤¯à¥‹ à¤‘à¤¨à¤²à¤¾à¤‡à¤¨ à¤¡à¤¾à¤‰à¤¨à¤²à¥‹à¤¡"
            ],
            'tutorial_lists': [
                "2025 à¤•à¥‡ à¤¬à¥‡à¤¸à¥à¤Ÿ à¤•à¥à¤†à¤ˆà¤¶à¥Œ à¤µà¥€à¤¡à¤¿à¤¯à¥‹ à¤¡à¤¾à¤‰à¤¨à¤²à¥‹à¤¡à¤°",
                "à¤•à¥à¤†à¤ˆà¤¶à¥Œ à¤µà¥€à¤¡à¤¿à¤¯à¥‹ à¤¡à¤¾à¤‰à¤¨à¤²à¥‹à¤¡ à¤•à¥‡ 5 à¤†à¤¸à¤¾à¤¨ à¤¤à¤°à¥€à¤•à¥‡"
            ],
            'feature_content': [
                "à¤•à¥à¤†à¤ˆà¤¶à¥Œ à¤µà¥€à¤¡à¤¿à¤¯à¥‹ à¤¡à¤¾à¤‰à¤¨à¤²à¥‹à¤¡ à¤«à¥€à¤šà¤°à¥à¤¸ à¤•à¥€ à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€",
                "à¤•à¥à¤†à¤ˆà¤¶à¥Œ à¤¡à¤¾à¤‰à¤¨à¤²à¥‹à¤¡à¤° à¤•à¥€ à¤µà¤¿à¤¶à¥‡à¤·à¤¤à¤¾à¤à¤‚"
            ]
        }
    elif "urdu" in language.lower() or "Ø§Ø±Ø¯Ùˆ" in language:
        base_topics = {
            'search_keywords': [
                "Kuaishou video download kaise kare",
                "iPhone mein Kuaishou video download",
                "Kuaishou video downloader app",
                "Free Kuaishou video download",
                "Android mein Kuaishou video save",
                "HD Kuaishou video download",
                "Online Kuaishou video download"
            ],
            'tutorial_lists': [
                "Best Kuaishou Video Downloaders 2025",
                "Kuaishou Video Download ke 5 Tarike"
            ],
            'feature_content': [
                "Kuaishou Video Download Features"
            ]
        }
    elif "indonesian" in language.lower() or "bahasa" in language.lower():
        base_topics = {
            'search_keywords': [
                "Cara download video Kuaishou",
                "Download video Kuaishou di iPhone",
                "Aplikasi download video Kuaishou",
                "Download video Kuaishou gratis",
                "Simpan video Kuaishou di Android",
                "Download video Kuaishou HD",
                "Download video Kuaishou online"
            ],
            'tutorial_lists': [
                "5 Aplikasi Download Video Kuaishou Terbaik 2025",
                "Cara Download Video Kuaishou Tanpa Watermark"
            ],
            'feature_content': [
                "Fitur Download Video Kuaishou"
            ]
        }
    elif "chinese" in language.lower() or "ä¸­æ–‡" in language:
        base_topics = {
            'search_keywords': [
                "å¦‚ä½•åœ¨iPhoneä¸Šä¸‹è½½å¿«æ‰‹è§†é¢‘",
                "å¿«æ‰‹è§†é¢‘ä¸‹è½½å™¨å“ªä¸ªæœ€å¥½ç”¨",
                "å…è´¹ä¸‹è½½å¿«æ‰‹è§†é¢‘çš„æ–¹æ³•",
                "å®‰å“æ‰‹æœºä¸‹è½½å¿«æ‰‹è§†é¢‘",
                "å¿«æ‰‹è§†é¢‘æ— æ°´å°ä¸‹è½½",
                "åœ¨çº¿å¿«æ‰‹è§†é¢‘ä¸‹è½½å·¥å…·",
                "å¿«æ‰‹çŸ­è§†é¢‘ä¿å­˜æ–¹æ³•"
            ],
            'tutorial_lists': [
                "2025å¹´æœ€ä½³å¿«æ‰‹è§†é¢‘ä¸‹è½½å·¥å…·TOP5",
                "å¿«æ‰‹è§†é¢‘ä¸‹è½½å®Œæ•´æ•™ç¨‹"
            ],
            'feature_content': [
                "å¿«æ‰‹è§†é¢‘ä¸‹è½½åŠŸèƒ½è¯¦è§£"
            ]
        }
    else:  # English
        base_topics = {
            'search_keywords': [
                "How to download Kuaishou videos on iPhone",
                "Best Kuaishou video downloader 2024",
                "Free Kuaishou video download methods",
                "Download Kuaishou videos on Android",
                "Kuaishou video downloader without watermark",
                "Online Kuaishou video download tool",
                "Save Kuaishou videos to phone"
            ],
            'tutorial_lists': [
                "Top 5 Kuaishou Video Downloaders 2025",
                "Complete Guide to Kuaishou Video Download"
            ],
            'feature_content': [
                "Kuaishou Video Download Features Explained"
            ]
        }

    # æ ¹æ®ç›®æ ‡æ•°é‡åˆ†é…é¢˜ç›®
    if target_count <= 3:
        search_count = target_count
        tutorial_count = 0
        feature_count = 0
    elif target_count <= 5:
        search_count = target_count - 1
        tutorial_count = 1
        feature_count = 0
    elif target_count <= 8:
        search_count = target_count - 2
        tutorial_count = 1
        feature_count = 1
    else:
        search_count = target_count - 3
        tutorial_count = 2
        feature_count = 1

    return {
        'search_keywords': base_topics['search_keywords'][:search_count],
        'tutorial_lists': base_topics['tutorial_lists'][:tutorial_count],
        'feature_content': base_topics['feature_content'][:feature_count]
    }

def get_default_category_topics(language: str) -> Dict[str, List[str]]:
    """è·å–é»˜è®¤åˆ†ç±»é¢˜ç›®"""
    return get_default_category_topics_with_count(language, 5)

def build_keywords_context(expanded_keywords: Dict[str, List[str]]) -> str:
    """æ„å»ºå…³é”®è¯ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²"""
    context_lines = []
    context_lines.append("ç›¸å…³å…³é”®è¯é›†åˆ:")
    
    for seed, suggestions in expanded_keywords.items():
        context_lines.append(f"â€¢ {seed}")
        for suggestion in suggestions[:5]:  # æ¯ä¸ªç§å­è¯æœ€å¤š5ä¸ªå»ºè®®
            context_lines.append(f"  - {suggestion}")
    
    return '\n'.join(context_lines)

def extract_delimiter_content(text, start_delimiter, end_delimiter):
    """æå–åˆ†éš”ç¬¦ä¹‹é—´çš„å†…å®¹ï¼Œå¹¶è¿›è¡Œæ¸…ç†"""
    start_index = text.find(start_delimiter)
    if start_index == -1:
        return None
    start_index += len(start_delimiter)

    end_index = text.find(end_delimiter, start_index)
    if end_index == -1:
        return None

    content = text[start_index:end_index].strip()

    # æ¸…ç†å¯èƒ½æ®‹ç•™çš„æ ¼å¼æ ‡è®°
    content = clean_content_markers(content)

    return content

def clean_content_markers(content):
    """æ¸…ç†å†…å®¹ä¸­çš„æ ¼å¼æ ‡è®°"""
    import re

    # ç§»é™¤æ‰€æœ‰===æ ‡è®°
    content = re.sub(r'===.*?===', '', content, flags=re.DOTALL)

    # ç§»é™¤å¤šä½™çš„ç©ºè¡Œ
    content = re.sub(r'\n\s*\n\s*\n', '\n\n', content)

    # æ¸…ç†å¼€å¤´å’Œç»“å°¾çš„ç©ºç™½
    content = content.strip()

    return content

def validate_and_clean_content(content, content_type="content"):
    """éªŒè¯å¹¶æ¸…ç†å†…å®¹ï¼Œç¡®ä¿æ²¡æœ‰æ ¼å¼æ ‡è®°"""
    if not content:
        return content

    # æ£€æŸ¥æ˜¯å¦åŒ…å«æ ¼å¼æ ‡è®°
    if "===" in content:
        print(f"âš ï¸ æ£€æµ‹åˆ°{content_type}ä¸­åŒ…å«æ ¼å¼æ ‡è®°ï¼Œæ­£åœ¨æ¸…ç†...")
        content = clean_content_markers(content)
        print(f"âœ… {content_type}æ¸…ç†å®Œæˆ")

    return content

def final_content_validation(title, description, content):
    """æœ€ç»ˆå†…å®¹éªŒè¯ï¼Œç¡®ä¿æ‰€æœ‰å†…å®¹éƒ½ç¬¦åˆè¦æ±‚"""
    issues = []

    # æ£€æŸ¥æ˜¯å¦åŒ…å«æ ¼å¼æ ‡è®°
    for field_name, field_content in [("æ ‡é¢˜", title), ("æè¿°", description), ("å†…å®¹", content)]:
        if field_content and "===" in field_content:
            issues.append(f"{field_name}åŒ…å«æ ¼å¼æ ‡è®°")

    # æ£€æŸ¥å†…å®¹é•¿åº¦
    if not content or len(content.strip()) < 100:
        issues.append("å†…å®¹è¿‡çŸ­")

    # æ£€æŸ¥æ ‡é¢˜é•¿åº¦
    if not title or len(title.strip()) < 5:
        issues.append("æ ‡é¢˜è¿‡çŸ­")

    # æ£€æŸ¥æè¿°é•¿åº¦
    if not description or len(description.strip()) < 20:
        issues.append("æè¿°è¿‡çŸ­")

    # æ£€æŸ¥æ˜¯å¦åŒ…å«å“ç‰Œç›¸å…³å†…å®¹
    brand_keywords = ["kuaishou", "å¿«æ‰‹", "video", "download"]
    content_lower = content.lower() if content else ""
    if not any(keyword in content_lower for keyword in brand_keywords):
        issues.append("å†…å®¹ç¼ºå°‘å“ç‰Œç›¸å…³å…³é”®è¯")

    if issues:
        return {
            "valid": False,
            "reason": "; ".join(issues)
        }

    return {
        "valid": True,
        "reason": "å†…å®¹éªŒè¯é€šè¿‡"
    }

def generate_slug(title):
    """ç”ŸæˆURLå‹å¥½çš„slug"""
    import re
    slug = title.lower()
    slug = re.sub(r'[^\w\s-]', '', slug)
    slug = re.sub(r'[-\s]+', '-', slug)
    return slug.strip('-')

def generate_unique_slug(base_slug, locale):
    """ç”Ÿæˆå”¯ä¸€çš„slug"""
    slug = base_slug
    counter = 1
    
    while True:
        result = supabase.table("posts").select("slug").eq("slug", slug).eq("locale", locale).execute()
        if not result.data:
            break
        slug = f"{base_slug}-{counter}"
        counter += 1
        
    return slug

def generate_article(topic, language, locale, keywords_context=""):
    """ç”Ÿæˆå•ç¯‡æ–‡ç« ï¼Œå¸¦é‡è¯•æœºåˆ¶"""
    max_retries = 2  # æœ€å¤šé‡è¯•2æ¬¡

    for attempt in range(max_retries + 1):
        try:
            if attempt > 0:
                print(f"ğŸ”„ ç¬¬{attempt + 1}æ¬¡å°è¯•ç”Ÿæˆæ–‡ç« : {topic}")

            return _generate_article_attempt(topic, language, locale, keywords_context)

        except Exception as e:
            error_msg = str(e)
            if "æ ¼å¼æ ‡è®°" in error_msg and attempt < max_retries:
                print(f"âš ï¸ ç¬¬{attempt + 1}æ¬¡å°è¯•å¤±è´¥ï¼ˆæ ¼å¼æ ‡è®°é—®é¢˜ï¼‰ï¼Œå‡†å¤‡é‡è¯•...")
                continue
            else:
                # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼Œæˆ–è€…éæ ¼å¼æ ‡è®°é—®é¢˜
                print(f"âŒ {language}æ–‡ç« ç”Ÿæˆå¤±è´¥ '{topic}': {e}")
                return {
                    "success": False,
                    "topic": topic,
                    "error": str(e),
                }

def _generate_article_attempt(topic, language, locale, keywords_context=""):
    """å•æ¬¡æ–‡ç« ç”Ÿæˆå°è¯•"""
    print(f"æ­£åœ¨ç”Ÿæˆ{language}æ–‡ç« : {topic}")

    # è·å–ç°æœ‰æ–‡ç« ä½œä¸ºå†…é“¾å‚è€ƒ
    existing_posts = supabase.table("posts").select("title, slug, locale").eq("status", "online").eq("locale", locale).limit(10).execute()

    internal_links_text = ""
    if existing_posts.data:
        if locale == "en":
            internal_links_text = "\n## Existing Articles (for internal linking):\n"
            for post in existing_posts.data:
                url = f"{SITE_URL}/posts/{post['slug']}"
                internal_links_text += f"- [{post['title']}]({url})\n"
        else:
            internal_links_text = "\n## ç°æœ‰æ–‡ç« åˆ—è¡¨ï¼ˆç”¨äºå†…é“¾å‚è€ƒï¼‰ï¼š\n"
            for post in existing_posts.data:
                url = f"{SITE_URL}/zh/posts/{post['slug']}"
                internal_links_text += f"- [{post['title']}]({url})\n"

    model = GenerativeModel("gemini-2.5-flash-preview-05-20")

    # æ„å»ºå…³é”®è¯ä¸Šä¸‹æ–‡
    keywords_section = ""
    if keywords_context:
        keywords_section = f"""

## å…³é”®è¯ä¼˜åŒ–æŒ‡å¯¼
åŸºäºä»¥ä¸‹ç›¸å…³å…³é”®è¯ä¼˜åŒ–ä½ çš„å†…å®¹ï¼š
{keywords_context}

**å…³é”®è¯ä½¿ç”¨è¦æ±‚ï¼š**
- è‡ªç„¶åœ°å°†è¿™äº›å…³é”®è¯èå…¥æ–‡ç« ä¸­
- åœ¨æ ‡é¢˜ã€å°æ ‡é¢˜å’Œæ­£æ–‡ä¸­åˆç†åˆ†å¸ƒå…³é”®è¯
- ç¡®ä¿å…³é”®è¯ä½¿ç”¨ä¸å½±å“å†…å®¹çš„è‡ªç„¶æ€§å’Œå¯è¯»æ€§
- ä¼˜å…ˆä½¿ç”¨é•¿å°¾å…³é”®è¯å’Œè¯­ä¹‰ç›¸å…³çš„è¯æ±‡"""

    # æ ¹æ®è¯­è¨€å’Œåœ°åŒºè®¾ç½®æç¤ºè¯
    if locale == "en":
        prompt = f"""You are a professional SEO content creator specializing in KuaishouVideoDownload (Kuaishou video downloader) related content.

## Task
Please create a high-quality SEO blog article for this topic: {topic}

## Requirements
- Article length: 1000-1500 words
- Language: English
- Natural, fluent writing style that avoids AI-generated traces
- Use Markdown format
- Include proper heading structure (H1, H2, H3)
- Must include at least 3 internal links to our existing related articles
- Include 2-3 high-quality external links (to authoritative websites)
- SEO optimized with naturally integrated relevant keywords

{internal_links_text}

{keywords_section}

## Internal Link Requirements
- Must naturally insert at least 3 links to the above existing articles within the content
- Internal links should be relevant to the article content and naturally integrated into paragraphs
- Use descriptive anchor text, not just "click here"
- Link format: [anchor text](URL)

## External Link Requirements
- Include 2-3 links to authoritative websites
- External links should be related to Kuaishou, video downloading, social media
- Add appropriate context for external links

## Output Format
Use the following delimiter format:

===TITLE_START===
[SEO-optimized title, max 60 characters]
===TITLE_END===

===SLUG_START===
[URL-friendly English slug, e.g., kuaishou-video-download-guide]
===SLUG_END===

===DESCRIPTION_START===
[Meta description, 150-160 characters, engaging summary]
===DESCRIPTION_END===

===CONTENT_START===
[Complete article content in Markdown format, must include at least 3 internal links and 2-3 external links]
===CONTENT_END===

Please generate natural, fluent content that avoids obvious AI-generated traces:

(Internal note for uniqueness: {int(time.time())})"""

    elif locale == "hi":
        prompt = f"""à¤†à¤ª à¤à¤• à¤ªà¥‡à¤¶à¥‡à¤µà¤° SEO à¤•à¤‚à¤Ÿà¥‡à¤‚à¤Ÿ à¤•à¥à¤°à¤¿à¤à¤Ÿà¤° à¤¹à¥ˆà¤‚ à¤œà¥‹ KuaishouVideoDownload (à¤•à¥à¤†à¤ˆà¤¶à¥Œ à¤µà¥€à¤¡à¤¿à¤¯à¥‹ à¤¡à¤¾à¤‰à¤¨à¤²à¥‹à¤¡à¤°) à¤¸à¤‚à¤¬à¤‚à¤§à¤¿à¤¤ à¤•à¤‚à¤Ÿà¥‡à¤‚à¤Ÿ à¤®à¥‡à¤‚ à¤µà¤¿à¤¶à¥‡à¤·à¤œà¥à¤ à¤¹à¥ˆà¤‚à¥¤

## à¤•à¤¾à¤°à¥à¤¯
à¤‡à¤¸ à¤µà¤¿à¤·à¤¯ à¤ªà¤° à¤à¤• à¤‰à¤šà¥à¤š à¤—à¥à¤£à¤µà¤¤à¥à¤¤à¤¾ à¤µà¤¾à¤²à¤¾ SEO à¤¬à¥à¤²à¥‰à¤— à¤²à¥‡à¤– à¤¬à¤¨à¤¾à¤à¤‚: {topic}

## à¤†à¤µà¤¶à¥à¤¯à¤•à¤¤à¤¾à¤à¤‚
- à¤²à¥‡à¤– à¤•à¥€ à¤²à¤‚à¤¬à¤¾à¤ˆ: 1000-1500 à¤¶à¤¬à¥à¤¦
- à¤­à¤¾à¤·à¤¾: à¤¹à¤¿à¤‚à¤¦à¥€
- à¤ªà¥à¤°à¤¾à¤•à¥ƒà¤¤à¤¿à¤•, à¤§à¤¾à¤°à¤¾à¤ªà¥à¤°à¤µà¤¾à¤¹ à¤²à¥‡à¤–à¤¨ à¤¶à¥ˆà¤²à¥€ à¤œà¥‹ AI-à¤œà¤¨à¤°à¥‡à¤Ÿà¥‡à¤¡ à¤¨à¤¿à¤¶à¤¾à¤¨ à¤¸à¥‡ à¤¬à¤šà¥‡
- Markdown à¤«à¥‰à¤°à¥à¤®à¥‡à¤Ÿ à¤•à¤¾ à¤‰à¤ªà¤¯à¥‹à¤— à¤•à¤°à¥‡à¤‚
- à¤‰à¤šà¤¿à¤¤ à¤¶à¥€à¤°à¥à¤·à¤• à¤¸à¤‚à¤°à¤šà¤¨à¤¾ à¤¶à¤¾à¤®à¤¿à¤² à¤•à¤°à¥‡à¤‚ (H1, H2, H3)
- à¤¹à¤®à¤¾à¤°à¥‡ à¤®à¥Œà¤œà¥‚à¤¦à¤¾ à¤¸à¤‚à¤¬à¤‚à¤§à¤¿à¤¤ à¤²à¥‡à¤–à¥‹à¤‚ à¤•à¥‡ à¤²à¤¿à¤ à¤•à¤® à¤¸à¥‡ à¤•à¤® 3 à¤†à¤‚à¤¤à¤°à¤¿à¤• à¤²à¤¿à¤‚à¤• à¤¶à¤¾à¤®à¤¿à¤² à¤•à¤°à¤¨à¤¾ à¤†à¤µà¤¶à¥à¤¯à¤• à¤¹à¥ˆ
- 2-3 à¤‰à¤šà¥à¤š à¤—à¥à¤£à¤µà¤¤à¥à¤¤à¤¾ à¤µà¤¾à¤²à¥‡ à¤¬à¤¾à¤¹à¤°à¥€ à¤²à¤¿à¤‚à¤• à¤¶à¤¾à¤®à¤¿à¤² à¤•à¤°à¥‡à¤‚ (à¤ªà¥à¤°à¤¾à¤§à¤¿à¤•à¤°à¤£ à¤µà¥‡à¤¬à¤¸à¤¾à¤‡à¤Ÿà¥‹à¤‚ à¤•à¥‡ à¤²à¤¿à¤)
- à¤ªà¥à¤°à¤¾à¤¸à¤‚à¤—à¤¿à¤• à¤•à¥€à¤µà¤°à¥à¤¡ à¤•à¥‡ à¤¸à¤¾à¤¥ SEO à¤…à¤¨à¥à¤•à¥‚à¤²à¤¿à¤¤

{internal_links_text}

{keywords_section}

## à¤†à¤‚à¤¤à¤°à¤¿à¤• à¤²à¤¿à¤‚à¤• à¤†à¤µà¤¶à¥à¤¯à¤•à¤¤à¤¾à¤à¤‚
- à¤•à¤‚à¤Ÿà¥‡à¤‚à¤Ÿ à¤®à¥‡à¤‚ à¤‰à¤ªà¤°à¥‹à¤•à¥à¤¤ à¤®à¥Œà¤œà¥‚à¤¦à¤¾ à¤²à¥‡à¤–à¥‹à¤‚ à¤•à¥‡ à¤²à¤¿à¤ à¤•à¤® à¤¸à¥‡ à¤•à¤® 3 à¤²à¤¿à¤‚à¤• à¤ªà¥à¤°à¤¾à¤•à¥ƒà¤¤à¤¿à¤• à¤°à¥‚à¤ª à¤¸à¥‡ à¤¡à¤¾à¤²à¤¨à¤¾ à¤†à¤µà¤¶à¥à¤¯à¤• à¤¹à¥ˆ
- à¤†à¤‚à¤¤à¤°à¤¿à¤• à¤²à¤¿à¤‚à¤• à¤²à¥‡à¤– à¤•à¤‚à¤Ÿà¥‡à¤‚à¤Ÿ à¤¸à¥‡ à¤¸à¤‚à¤¬à¤‚à¤§à¤¿à¤¤ à¤¹à¥‹à¤¨à¥‡ à¤šà¤¾à¤¹à¤¿à¤ à¤”à¤° à¤ªà¥ˆà¤°à¤¾à¤—à¥à¤°à¤¾à¤« à¤®à¥‡à¤‚ à¤ªà¥à¤°à¤¾à¤•à¥ƒà¤¤à¤¿à¤• à¤°à¥‚à¤ª à¤¸à¥‡ à¤à¤•à¥€à¤•à¥ƒà¤¤ à¤¹à¥‹à¤¨à¥‡ à¤šà¤¾à¤¹à¤¿à¤
- à¤µà¤°à¥à¤£à¤¨à¤¾à¤¤à¥à¤®à¤• à¤à¤‚à¤•à¤° à¤Ÿà¥‡à¤•à¥à¤¸à¥à¤Ÿ à¤•à¤¾ à¤‰à¤ªà¤¯à¥‹à¤— à¤•à¤°à¥‡à¤‚, à¤•à¥‡à¤µà¤² "à¤¯à¤¹à¤¾à¤‚ à¤•à¥à¤²à¤¿à¤• à¤•à¤°à¥‡à¤‚" à¤¨à¤¹à¥€à¤‚
- à¤²à¤¿à¤‚à¤• à¤«à¥‰à¤°à¥à¤®à¥‡à¤Ÿ: [à¤à¤‚à¤•à¤° à¤Ÿà¥‡à¤•à¥à¤¸à¥à¤Ÿ](URL)

## à¤¬à¤¾à¤¹à¤°à¥€ à¤²à¤¿à¤‚à¤• à¤†à¤µà¤¶à¥à¤¯à¤•à¤¤à¤¾à¤à¤‚
- à¤ªà¥à¤°à¤¾à¤§à¤¿à¤•à¤°à¤£ à¤µà¥‡à¤¬à¤¸à¤¾à¤‡à¤Ÿà¥‹à¤‚ à¤•à¥‡ à¤²à¤¿à¤ 2-3 à¤²à¤¿à¤‚à¤• à¤¶à¤¾à¤®à¤¿à¤² à¤•à¤°à¥‡à¤‚
- à¤¬à¤¾à¤¹à¤°à¥€ à¤²à¤¿à¤‚à¤• à¤•à¥à¤†à¤ˆà¤¶à¥Œ, à¤µà¥€à¤¡à¤¿à¤¯à¥‹ à¤¡à¤¾à¤‰à¤¨à¤²à¥‹à¤¡à¤¿à¤‚à¤—, à¤¸à¥‹à¤¶à¤² à¤®à¥€à¤¡à¤¿à¤¯à¤¾ à¤¸à¥‡ à¤¸à¤‚à¤¬à¤‚à¤§à¤¿à¤¤ à¤¹à¥‹à¤¨à¥‡ à¤šà¤¾à¤¹à¤¿à¤
- à¤¬à¤¾à¤¹à¤°à¥€ à¤²à¤¿à¤‚à¤• à¤•à¥‡ à¤²à¤¿à¤ à¤‰à¤šà¤¿à¤¤ à¤¸à¤‚à¤¦à¤°à¥à¤­ à¤œà¥‹à¤¡à¤¼à¥‡à¤‚

## à¤†à¤‰à¤Ÿà¤ªà¥à¤Ÿ à¤«à¥‰à¤°à¥à¤®à¥‡à¤Ÿ
à¤¨à¤¿à¤®à¥à¤¨à¤²à¤¿à¤–à¤¿à¤¤ à¤¡à¤¿à¤²à¤¿à¤®à¤¿à¤Ÿà¤° à¤«à¥‰à¤°à¥à¤®à¥‡à¤Ÿ à¤•à¤¾ à¤‰à¤ªà¤¯à¥‹à¤— à¤•à¤°à¥‡à¤‚:

===TITLE_START===
[SEO-à¤…à¤¨à¥à¤•à¥‚à¤²à¤¿à¤¤ à¤¶à¥€à¤°à¥à¤·à¤•, à¤…à¤§à¤¿à¤•à¤¤à¤® 60 à¤µà¤°à¥à¤£]
===TITLE_END===

===SLUG_START===
[URL-à¤«à¥à¤°à¥‡à¤‚à¤¡à¤²à¥€ à¤…à¤‚à¤—à¥à¤°à¥‡à¤œà¥€ slug, à¤œà¥ˆà¤¸à¥‡: kuaishou-video-download-hindi-guide]
===SLUG_END===

===DESCRIPTION_START===
[à¤®à¥‡à¤Ÿà¤¾ à¤µà¤¿à¤µà¤°à¤£, 150-160 à¤µà¤°à¥à¤£, à¤†à¤•à¤°à¥à¤·à¤• à¤¸à¤¾à¤°à¤¾à¤‚à¤¶]
===DESCRIPTION_END===

===CONTENT_START===
[Markdown à¤«à¥‰à¤°à¥à¤®à¥‡à¤Ÿ à¤®à¥‡à¤‚ à¤ªà¥‚à¤°à¤¾ à¤²à¥‡à¤– à¤•à¤‚à¤Ÿà¥‡à¤‚à¤Ÿ, à¤•à¤® à¤¸à¥‡ à¤•à¤® 3 à¤†à¤‚à¤¤à¤°à¤¿à¤• à¤²à¤¿à¤‚à¤• à¤”à¤° 2-3 à¤¬à¤¾à¤¹à¤°à¥€ à¤²à¤¿à¤‚à¤• à¤¶à¤¾à¤®à¤¿à¤² à¤•à¤°à¤¨à¤¾ à¤†à¤µà¤¶à¥à¤¯à¤• à¤¹à¥ˆ]
===CONTENT_END===

à¤•à¥ƒà¤ªà¤¯à¤¾ à¤ªà¥à¤°à¤¾à¤•à¥ƒà¤¤à¤¿à¤•, à¤§à¤¾à¤°à¤¾à¤ªà¥à¤°à¤µà¤¾à¤¹ à¤•à¤‚à¤Ÿà¥‡à¤‚à¤Ÿ à¤¬à¤¨à¤¾à¤à¤‚ à¤œà¥‹ à¤¸à¥à¤ªà¤·à¥à¤Ÿ AI-à¤œà¤¨à¤°à¥‡à¤Ÿà¥‡à¤¡ à¤¨à¤¿à¤¶à¤¾à¤¨ à¤¸à¥‡ à¤¬à¤šà¥‡:

(à¤µà¤¿à¤¶à¤¿à¤·à¥à¤Ÿà¤¤à¤¾ à¤•à¥‡ à¤²à¤¿à¤ à¤†à¤‚à¤¤à¤°à¤¿à¤• à¤¨à¥‹à¤Ÿ: {int(time.time())})"""

    elif locale == "bn":
        prompt = f"""Ø¢Ù¾ Ø§ÛŒÚ© Ù¾ÛŒØ´Û ÙˆØ± SEO Ú©Ù†Ù¹ÛŒÙ†Ù¹ Ú©Ø±ÛŒÙ¹Ø± ÛÛŒÚº Ø¬Ùˆ KuaishouVideoDownload (Ú©ÙˆØ§Ø¦ÛŒ Ø´Ùˆ ÙˆÛŒÚˆÛŒÙˆ ÚˆØ§Ø¤Ù† Ù„ÙˆÚˆØ±) Ø³Û’ Ù…ØªØ¹Ù„Ù‚ Ú©Ù†Ù¹ÛŒÙ†Ù¹ Ù…ÛŒÚº Ù…ÛØ§Ø±Øª Ø±Ú©Ú¾ØªÛ’ ÛÛŒÚºÛ”

## Ú©Ø§Ù…
Ø§Ø³ Ù…ÙˆØ¶ÙˆØ¹ Ù¾Ø± Ø§ÛŒÚ© Ø§Ø¹Ù„ÛŒÙ° Ù…Ø¹ÛŒØ§Ø± Ú©Ø§ SEO Ø¨Ù„Ø§Ú¯ Ù…Ø¶Ù…ÙˆÙ† Ø¨Ù†Ø§Ø¦ÛŒÚº: {topic}

## Ø¶Ø±ÙˆØ±ÛŒØ§Øª
- Ù…Ø¶Ù…ÙˆÙ† Ú©ÛŒ Ù„Ù…Ø¨Ø§Ø¦ÛŒ: 1000-1500 Ø§Ù„ÙØ§Ø¸
- Ø²Ø¨Ø§Ù†: Ø§Ø±Ø¯Ùˆ
- Ù‚Ø¯Ø±ØªÛŒØŒ Ø±ÙˆØ§Ù†ÛŒ Ø³Û’ Ù„Ú©Ú¾Ù†Û’ Ú©Ø§ Ø§Ù†Ø¯Ø§Ø² Ø¬Ùˆ AI-generated Ù†Ø´Ø§Ù†Ø§Øª Ø³Û’ Ø¨Ú†Û’
- Markdown ÙØ§Ø±Ù…ÛŒÙ¹ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ÛŒÚº
- Ù…Ù†Ø§Ø³Ø¨ Ø¹Ù†ÙˆØ§Ù† Ú©ÛŒ Ø³Ø§Ø®Øª Ø´Ø§Ù…Ù„ Ú©Ø±ÛŒÚº (H1, H2, H3)
- ÛÙ…Ø§Ø±Û’ Ù…ÙˆØ¬ÙˆØ¯Û Ù…ØªØ¹Ù„Ù‚Û Ù…Ø¶Ø§Ù…ÛŒÙ† Ú©Û’ Ù„ÛŒÛ’ Ú©Ù… Ø§Ø² Ú©Ù… 3 Ø§Ù†Ø¯Ø±ÙˆÙ†ÛŒ Ù„Ù†Ú©Ø³ Ø´Ø§Ù…Ù„ Ú©Ø±Ù†Ø§ Ø¶Ø±ÙˆØ±ÛŒ ÛÛ’
- 2-3 Ø§Ø¹Ù„ÛŒÙ° Ù…Ø¹ÛŒØ§Ø± Ú©Û’ Ø¨ÛŒØ±ÙˆÙ†ÛŒ Ù„Ù†Ú©Ø³ Ø´Ø§Ù…Ù„ Ú©Ø±ÛŒÚº (Ù…Ø³ØªÙ†Ø¯ ÙˆÛŒØ¨ Ø³Ø§Ø¦Ù¹Ø³ Ú©Û’ Ù„ÛŒÛ’)
- Ù…ØªØ¹Ù„Ù‚Û Ú©Ù„ÛŒØ¯ÛŒ Ø§Ù„ÙØ§Ø¸ Ú©Û’ Ø³Ø§ØªÚ¾ SEO Ú©Û’ Ù„ÛŒÛ’ Ù…ÙˆØ²ÙˆÚº

{internal_links_text}

{keywords_section}

## Ø§Ù†Ø¯Ø±ÙˆÙ†ÛŒ Ù„Ù†Ú© Ú©ÛŒ Ø¶Ø±ÙˆØ±ÛŒØ§Øª
- Ú©Ù†Ù¹ÛŒÙ†Ù¹ Ù…ÛŒÚº Ø§ÙˆÙ¾Ø± Ø¯ÛŒÛ’ Ú¯Ø¦Û’ Ù…ÙˆØ¬ÙˆØ¯Û Ù…Ø¶Ø§Ù…ÛŒÙ† Ú©Û’ Ù„ÛŒÛ’ Ú©Ù… Ø§Ø² Ú©Ù… 3 Ù„Ù†Ú©Ø³ Ù‚Ø¯Ø±ØªÛŒ Ø·ÙˆØ± Ù¾Ø± Ø¯Ø§Ø®Ù„ Ú©Ø±Ù†Ø§ Ø¶Ø±ÙˆØ±ÛŒ ÛÛ’
- Ø§Ù†Ø¯Ø±ÙˆÙ†ÛŒ Ù„Ù†Ú©Ø³ Ù…Ø¶Ù…ÙˆÙ† Ú©Û’ Ú©Ù†Ù¹ÛŒÙ†Ù¹ Ø³Û’ Ù…ØªØ¹Ù„Ù‚ ÛÙˆÙ†Û’ Ú†Ø§ÛÛŒÛ’ Ø§ÙˆØ± Ù¾ÛŒØ±Ø§Ú¯Ø±Ø§ÙØ³ Ù…ÛŒÚº Ù‚Ø¯Ø±ØªÛŒ Ø·ÙˆØ± Ù¾Ø± Ø´Ø§Ù…Ù„ ÛÙˆÙ†Û’ Ú†Ø§ÛÛŒÛ’
- ÙˆØ¶Ø§Ø­ØªÛŒ anchor text Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ÛŒÚºØŒ ØµØ±Ù "ÛŒÛØ§Úº Ú©Ù„Ú© Ú©Ø±ÛŒÚº" Ù†ÛÛŒÚº
- Ù„Ù†Ú© ÙØ§Ø±Ù…ÛŒÙ¹: [anchor text](URL)

## Ø¨ÛŒØ±ÙˆÙ†ÛŒ Ù„Ù†Ú© Ú©ÛŒ Ø¶Ø±ÙˆØ±ÛŒØ§Øª
- Ù…Ø³ØªÙ†Ø¯ ÙˆÛŒØ¨ Ø³Ø§Ø¦Ù¹Ø³ Ú©Û’ Ù„ÛŒÛ’ 2-3 Ù„Ù†Ú©Ø³ Ø´Ø§Ù…Ù„ Ú©Ø±ÛŒÚº
- Ø¨ÛŒØ±ÙˆÙ†ÛŒ Ù„Ù†Ú©Ø³ Ú©ÙˆØ§Ø¦ÛŒ Ø´ÙˆØŒ ÙˆÛŒÚˆÛŒÙˆ ÚˆØ§Ø¤Ù† Ù„ÙˆÚˆÙ†Ú¯ØŒ Ø³ÙˆØ´Ù„ Ù…ÛŒÚˆÛŒØ§ Ø³Û’ Ù…ØªØ¹Ù„Ù‚ ÛÙˆÙ†Û’ Ú†Ø§ÛÛŒÛ’
- Ø¨ÛŒØ±ÙˆÙ†ÛŒ Ù„Ù†Ú©Ø³ Ú©Û’ Ù„ÛŒÛ’ Ù…Ù†Ø§Ø³Ø¨ Ø³ÛŒØ§Ù‚ Ùˆ Ø³Ø¨Ø§Ù‚ Ø´Ø§Ù…Ù„ Ú©Ø±ÛŒÚº

## Ø¢Ø¤Ù¹ Ù¾Ù¹ ÙØ§Ø±Ù…ÛŒÙ¹
Ù…Ù†Ø¯Ø±Ø¬Û Ø°ÛŒÙ„ delimiter ÙØ§Ø±Ù…ÛŒÙ¹ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ÛŒÚº:

===TITLE_START===
[SEO Ú©Û’ Ù„ÛŒÛ’ Ù…ÙˆØ²ÙˆÚº Ø¹Ù†ÙˆØ§Ù†ØŒ Ø²ÛŒØ§Ø¯Û Ø³Û’ Ø²ÛŒØ§Ø¯Û 60 Ø­Ø±ÙˆÙ]
===TITLE_END===

===SLUG_START===
[URL-friendly Ø§Ù†Ú¯Ø±ÛŒØ²ÛŒ slugØŒ Ø¬ÛŒØ³Û’: kuaishou-video-download-bengali-guide]
===SLUG_END===

===DESCRIPTION_START===
[Ù…ÛŒÙ¹Ø§ ØªÙØµÛŒÙ„ØŒ 150-160 Ø­Ø±ÙˆÙØŒ Ø¯Ù„Ú†Ø³Ù¾ Ø®Ù„Ø§ØµÛ]
===DESCRIPTION_END===

===CONTENT_START===
[Markdown ÙØ§Ø±Ù…ÛŒÙ¹ Ù…ÛŒÚº Ù…Ú©Ù…Ù„ Ù…Ø¶Ù…ÙˆÙ† Ú©Ø§ Ú©Ù†Ù¹ÛŒÙ†Ù¹ØŒ Ú©Ù… Ø§Ø² Ú©Ù… 3 Ø§Ù†Ø¯Ø±ÙˆÙ†ÛŒ Ù„Ù†Ú©Ø³ Ø§ÙˆØ± 2-3 Ø¨ÛŒØ±ÙˆÙ†ÛŒ Ù„Ù†Ú©Ø³ Ø´Ø§Ù…Ù„ Ú©Ø±Ù†Ø§ Ø¶Ø±ÙˆØ±ÛŒ ÛÛ’]
===CONTENT_END===

Ø¨Ø±Ø§Û Ú©Ø±Ù… Ù‚Ø¯Ø±ØªÛŒØŒ Ø±ÙˆØ§Ù†ÛŒ ÙˆØ§Ù„Ø§ Ú©Ù†Ù¹ÛŒÙ†Ù¹ Ø¨Ù†Ø§Ø¦ÛŒÚº Ø¬Ùˆ ÙˆØ§Ø¶Ø­ AI-generated Ù†Ø´Ø§Ù†Ø§Øª Ø³Û’ Ø¨Ú†Û’:

(Ù…Ù†ÙØ±Ø¯ÛŒØª Ú©Û’ Ù„ÛŒÛ’ Ø§Ù†Ø¯Ø±ÙˆÙ†ÛŒ Ù†ÙˆÙ¹: {int(time.time())})"""

    elif locale == "id":
        prompt = f"""Anda adalah seorang pembuat konten SEO profesional yang mengkhususkan diri dalam konten terkait KuaishouVideoDownload (pengunduh video Kuaishou).

## Tugas
Buatlah artikel blog SEO berkualitas tinggi untuk topik ini: {topic}

## Persyaratan
- Panjang artikel: 1000-1500 kata
- Bahasa: Bahasa Indonesia
- Gaya penulisan yang alami dan lancar yang menghindari jejak AI-generated
- Gunakan format Markdown
- Sertakan struktur judul yang tepat (H1, H2, H3)
- Harus menyertakan setidaknya 3 tautan internal ke artikel terkait yang sudah ada
- Sertakan 2-3 tautan eksternal berkualitas tinggi (ke situs web otoritatif)
- Dioptimalkan SEO dengan kata kunci relevan yang terintegrasi secara alami

{internal_links_text}

{keywords_section}

## Persyaratan Tautan Internal
- Harus secara alami menyisipkan setidaknya 3 tautan ke artikel yang sudah ada di atas dalam konten
- Tautan internal harus relevan dengan konten artikel dan terintegrasi secara alami ke dalam paragraf
- Gunakan anchor text yang deskriptif, bukan hanya "klik di sini"
- Format tautan: [anchor text](URL)

## Persyaratan Tautan Eksternal
- Sertakan 2-3 tautan ke situs web otoritatif
- Tautan eksternal harus terkait dengan Kuaishou, pengunduhan video, media sosial
- Tambahkan konteks yang tepat untuk tautan eksternal

## Format Output
Gunakan format delimiter berikut:

===TITLE_START===
[Judul yang dioptimalkan SEO, maksimal 60 karakter]
===TITLE_END===

===SLUG_START===
[Slug bahasa Inggris yang ramah URL, misalnya: kuaishou-video-download-indonesian-guide]
===SLUG_END===

===DESCRIPTION_START===
[Deskripsi meta, 150-160 karakter, ringkasan yang menarik]
===DESCRIPTION_END===

===CONTENT_START===
[Konten artikel lengkap dalam format Markdown, harus menyertakan setidaknya 3 tautan internal dan 2-3 tautan eksternal]
===CONTENT_END===

Harap buat konten yang alami dan lancar yang menghindari jejak AI-generated yang jelas:

(Catatan internal untuk keunikan: {int(time.time())})"""

    else:  # Default to Chinese
        prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„SEOæ–‡ç« åˆ›ä½œè€…ï¼Œä¸“æ³¨äº KuaishouVideoDownloadï¼ˆå¿«æ‰‹è§†é¢‘ä¸‹è½½å™¨ï¼‰ç›¸å…³å†…å®¹åˆ›ä½œã€‚

        ## ä»»åŠ¡
        è¯·ä¸ºä»¥ä¸‹é¢˜ç›®åˆ›ä½œä¸€ç¯‡é«˜è´¨é‡çš„SEOåšå®¢æ–‡ç« ï¼š{topic}

        ## è¦æ±‚
        - æ–‡ç« é•¿åº¦ï¼š1000-1500å­—
        - è¯­è¨€ï¼šä¸­æ–‡
        - è‡ªç„¶æµç•…çš„å†™ä½œé£æ ¼ï¼Œé¿å…AIç”Ÿæˆçš„ç—•è¿¹
        - ä½¿ç”¨Markdownæ ¼å¼
        - åŒ…å«åˆé€‚çš„æ ‡é¢˜ç»“æ„ï¼ˆH1ã€H2ã€H3ï¼‰
        - å¿…é¡»åŒ…å«è‡³å°‘3ä¸ªå†…éƒ¨é“¾æ¥åˆ°æˆ‘ä»¬ç°æœ‰çš„ç›¸å…³æ–‡ç« 
        - åŒ…å«2-3ä¸ªé«˜è´¨é‡çš„å¤–éƒ¨é“¾æ¥ï¼ˆæŒ‡å‘æƒå¨ç½‘ç«™ï¼‰
        - SEOä¼˜åŒ–ï¼Œè‡ªç„¶èå…¥ç›¸å…³å…³é”®è¯

        {internal_links_text}

        {keywords_section}

        ## å†…é“¾è¦æ±‚
        - å¿…é¡»åœ¨å†…å®¹ä¸­è‡ªç„¶æ’å…¥è‡³å°‘3ä¸ªæŒ‡å‘ä¸Šè¿°ç°æœ‰æ–‡ç« çš„é“¾æ¥
        - å†…é“¾åº”ä¸æ–‡ç« å†…å®¹ç›¸å…³ï¼Œè‡ªç„¶èå…¥åˆ°æ®µè½ä¸­
        - ä½¿ç”¨æè¿°æ€§é”šæ–‡æœ¬ï¼Œä¸è¦åªæ˜¯"ç‚¹å‡»è¿™é‡Œ"
        - é“¾æ¥æ ¼å¼ï¼š[é”šæ–‡æœ¬](URL)

        ## å¤–é“¾è¦æ±‚
        - åŒ…å«2-3ä¸ªæŒ‡å‘æƒå¨ç½‘ç«™çš„é“¾æ¥
        - å¤–é“¾åº”ä¸å¿«æ‰‹ã€è§†é¢‘ä¸‹è½½ã€ç¤¾äº¤åª’ä½“ç›¸å…³
        - ä¸ºå¤–é“¾æ·»åŠ é€‚å½“çš„ä¸Šä¸‹æ–‡

        ## è¾“å‡ºæ ¼å¼
        ä½¿ç”¨ä»¥ä¸‹åˆ†éš”ç¬¦æ ¼å¼ï¼š

        ===TITLE_START===
        [SEOä¼˜åŒ–çš„æ ‡é¢˜ï¼Œæœ€å¤š60ä¸ªå­—ç¬¦]
        ===TITLE_END===

        ===SLUG_START===
        [URLå‹å¥½çš„è‹±è¯­slugï¼Œä¾‹å¦‚ï¼škuaishou-video-download-chinese-guide]
        ===SLUG_END===

        ===DESCRIPTION_START===
        [å…ƒæè¿°ï¼Œ150-160å­—ç¬¦ï¼Œå¸å¼•äººçš„æ‘˜è¦]
        ===DESCRIPTION_END===

        ===CONTENT_START===
        [å®Œæ•´çš„æ–‡ç« å†…å®¹ï¼ŒMarkdownæ ¼å¼ï¼Œå¿…é¡»åŒ…å«è‡³å°‘3ä¸ªå†…é“¾å’Œ2-3ä¸ªå¤–é“¾]
        ===CONTENT_END===

        è¯·ç”Ÿæˆè‡ªç„¶ã€æµç•…çš„å†…å®¹ï¼Œé¿å…æ˜æ˜¾çš„AIç”Ÿæˆç—•è¿¹ï¼š

        (å†…éƒ¨å”¯ä¸€æ€§æ ‡è¯†: {int(time.time())})"""

    result = model.generate_content(prompt)
    text = result.text

    if not text:
        raise Exception("AIæœªèƒ½ç”Ÿæˆæœ‰æ•ˆå†…å®¹")

    # è°ƒè¯•ï¼šæ˜¾ç¤ºåŸå§‹å“åº”çš„å‰å‡ è¡Œ
    print(f"ğŸ” åŸå§‹AIå“åº”é¢„è§ˆ:")
    preview_lines = text.split('\n')[:5]
    for i, line in enumerate(preview_lines, 1):
        print(f"   {i}. {line[:100]}{'...' if len(line) > 100 else ''}")

    # è§£æç”Ÿæˆçš„å†…å®¹
    title = extract_delimiter_content(text, "===TITLE_START===", "===TITLE_END===") or topic
    slug = extract_delimiter_content(text, "===SLUG_START===", "===SLUG_END===") or generate_slug(title)
    description = extract_delimiter_content(text, "===DESCRIPTION_START===", "===DESCRIPTION_END===") or f"å…³äº{title}çš„è¯¦ç»†æŒ‡å—"
    content = extract_delimiter_content(text, "===CONTENT_START===", "===CONTENT_END===")

    # å¦‚æœå†…å®¹è§£æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬ä½†è¿›è¡Œæ¸…ç†
    if not content:
        print("âš ï¸ å†…å®¹è§£æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬å¹¶æ¸…ç†æ ¼å¼æ ‡è®°")
        content = clean_content_markers(text)

    # äºŒæ¬¡éªŒè¯å’Œæ¸…ç†æ‰€æœ‰å­—æ®µ
    title = validate_and_clean_content(title, "æ ‡é¢˜")
    description = validate_and_clean_content(description, "æè¿°")
    content = validate_and_clean_content(content, "å†…å®¹")

    # ç¡®ä¿å†…å®¹ä¸ä¸ºç©º
    if not content or len(content.strip()) < 100:
        raise Exception("ç”Ÿæˆçš„å†…å®¹è¿‡çŸ­æˆ–ä¸ºç©º")

    # æœ€ç»ˆå®‰å…¨æ£€æŸ¥ - å¦‚æœæ£€æµ‹åˆ°æ ¼å¼æ ‡è®°ï¼Œç›´æ¥é‡æ–°ç”Ÿæˆ
    if "===" in content or "===" in title or "===" in description:
        print("âš ï¸ æ£€æµ‹åˆ°æ ¼å¼æ ‡è®°æ®‹ç•™ï¼Œé‡æ–°ç”Ÿæˆæ–‡ç« ...")
        raise Exception("å†…å®¹åŒ…å«æ ¼å¼æ ‡è®°ï¼Œéœ€è¦é‡æ–°ç”Ÿæˆ")

    # å…¶ä»–éªŒè¯
    final_validation_result = final_content_validation(title, description, content)
    if not final_validation_result["valid"]:
        raise Exception(f"å†…å®¹éªŒè¯å¤±è´¥: {final_validation_result['reason']}")

    # ç”Ÿæˆå”¯ä¸€slug
    final_slug = generate_unique_slug(slug, locale)

    # è·å–å°é¢å›¾ç‰‡ - ä½¿ç”¨çŸ­è§†é¢‘ç›¸å…³å…³é”®è¯
    cover_url = get_unsplash_image("short video")

    # ä¸ºæ–‡ç« æ·»åŠ éšæœºçš„æ—¶é—´åç§»ï¼Œè®©å‘å¸ƒæ—¶é—´æ›´è‡ªç„¶
    publish_time = datetime.now()
    random_hours_back = random.randint(1, 72)
    random_minutes_back = random.randint(1, 60)
    publish_time = publish_time.replace(hour=max(0, publish_time.hour - random_hours_back % 24))
    publish_time = publish_time.replace(minute=max(0, publish_time.minute - random_minutes_back % 60))

    # æ’å…¥åˆ°æ•°æ®åº“
    post_uuid = str(uuid.uuid4())
    insert_data = {
            "uuid": post_uuid,
            "slug": final_slug,
            "title": title,
            "description": description,
            "content": content,
            "cover_url": cover_url,
            "created_at": publish_time.isoformat(),
            "updated_at": publish_time.isoformat(),
            "status": "online",
            "locale": locale,
            "author_name": "KuaishouVideoDownload Team",
            "author_avatar_url": "https://www.kuaishou-video-download.com/logo.png"
        }

    result = supabase.table("posts").insert(insert_data).execute()

    if result.data:
        print(f"âœ… {language}æ–‡ç« ç”ŸæˆæˆåŠŸ: {title}")
        return {
            "success": True,
            "topic": topic,
            "title": title,
            "uuid": post_uuid,
            "slug": final_slug,
            "cover_url": cover_url,
        }
    else:
        raise Exception("æ•°æ®åº“æ’å…¥å¤±è´¥")

def generate_keyword_driven_articles(language: str, locale: str, target_count: int = 5) -> Dict[str, Any]:
    """å…³é”®è¯é©±åŠ¨çš„æ–‡ç« ç”Ÿæˆæµç¨‹"""
    try:
        print(f"\nğŸ¯ å¼€å§‹{language}å…³é”®è¯é©±åŠ¨çš„å†…å®¹ç”Ÿæˆæµç¨‹ï¼ˆç›®æ ‡ï¼š{target_count}ç¯‡ï¼‰...")

        # æ­¥éª¤1: ç”Ÿæˆç§å­å…³é”®è¯
        print(f"\nğŸ“Š æ­¥éª¤1: ç”Ÿæˆ{language}ç§å­å…³é”®è¯")
        seed_keywords = generate_seed_keywords(language, max(6, target_count))

        if not seed_keywords:
            print(f"âŒ {language}ç§å­å…³é”®è¯ç”Ÿæˆå¤±è´¥")
            return {"success": 0, "failure": 0, "topics": [], "results": []}

        print(f"ğŸ”‘ {language}ç§å­å…³é”®è¯:")
        for i, keyword in enumerate(seed_keywords, 1):
            print(f"   {i}. {keyword}")

        # æ­¥éª¤2: ä½¿ç”¨Googleè‡ªåŠ¨å®Œæˆæ‰©å±•å…³é”®è¯
        print(f"\nğŸ” æ­¥éª¤2: æ‰©å±•{language}å…³é”®è¯")
        expanded_keywords = expand_keywords_with_google(seed_keywords, 5)

        print(f"\nğŸ“ˆ {language}æ‰©å±•åçš„å…³é”®è¯é›†åˆ:")
        total_keywords = 0
        for seed, suggestions in expanded_keywords.items():
            print(f"   ğŸŒ± {seed}: {len(suggestions)}ä¸ªå»ºè®®")
            total_keywords += len(suggestions)
        print(f"   æ€»è®¡: {len(seed_keywords)}ä¸ªç§å­å…³é”®è¯ â†’ {total_keywords}ä¸ªæ‰©å±•å…³é”®è¯")

        # æ­¥éª¤3: åŸºäºå…³é”®è¯ç”Ÿæˆåˆ†ç±»æ–‡ç« é¢˜ç›®
        print(f"\nğŸ“ æ­¥éª¤3: ç”Ÿæˆ{language}åˆ†ç±»æ–‡ç« é¢˜ç›®")
        categorized_topics = generate_categorized_topics_by_keywords_with_count(expanded_keywords, language, target_count)

        print(f"\nğŸ“š {language}ç”Ÿæˆçš„åˆ†ç±»æ–‡ç« é¢˜ç›®:")
        all_topics = []
        for category, topics in categorized_topics.items():
            print(f"   ğŸ“‚ {category}: {len(topics)}ä¸ªé¢˜ç›®")
            for topic in topics:
                print(f"      â€¢ {topic}")
                all_topics.append((category, topic))

        # é™åˆ¶æ–‡ç« æ•°é‡åˆ°ç›®æ ‡æ•°é‡
        if len(all_topics) > target_count:
            all_topics = all_topics[:target_count]
            print(f"ğŸ“ é™åˆ¶æ–‡ç« æ•°é‡åˆ°ç›®æ ‡æ•°é‡: {target_count}ç¯‡")

        # æ­¥éª¤4: æ‰§è¡Œæ–‡ç« ç”Ÿæˆ
        print(f"\nğŸš€ æ­¥éª¤4: å¼€å§‹ç”Ÿæˆ{language}æ–‡ç« ...")

        # æ„å»ºå…³é”®è¯ä¸Šä¸‹æ–‡
        keywords_context = build_keywords_context(expanded_keywords)

        results = []
        success_count = 0
        failure_count = 0

        for category, topic in all_topics:
            topic_to_use = topic

            print(f"\nğŸ“ ç”Ÿæˆæ–‡ç« : {topic_to_use} (åˆ†ç±»: {category})")
            result = generate_article(topic_to_use, language, locale, keywords_context)
            results.append(result)

            if result["success"]:
                success_count += 1
                print(f"âœ… æˆåŠŸ: {result['title']}")
            else:
                failure_count += 1
                print(f"âŒ å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")

            # å»¶è¿Ÿé¿å…APIé™åˆ¶
            time.sleep(3)

        print(f"\nğŸ‰ {language}å…³é”®è¯é©±åŠ¨ç”Ÿæˆå®Œæˆ!")
        print(f"   ğŸ“Š ç§å­å…³é”®è¯: {len(seed_keywords)} ä¸ª")
        print(f"   ğŸ” æ‰©å±•å…³é”®è¯: {total_keywords} ä¸ª")
        print(f"   ğŸ“ æˆåŠŸç”Ÿæˆæ–‡ç« : {success_count} ç¯‡")
        print(f"   âŒ å¤±è´¥: {failure_count} ç¯‡")

        return {
            "success": success_count,
            "failure": failure_count,
            "topics": [topic for _, topic in all_topics],
            "results": results,
            "seed_keywords": seed_keywords,
            "expanded_keywords": expanded_keywords,
            "categorized_topics": categorized_topics
        }

    except Exception as e:
        print(f"âŒ {language}å…³é”®è¯é©±åŠ¨ç”Ÿæˆå¤±è´¥: {e}")
        return {"success": 0, "failure": 0, "topics": [], "results": []}

def main():
    """ä¸»å‡½æ•° - è‹±æ–‡æ–‡ç« ç”Ÿæˆ"""
    print("ğŸš€ å¼€å§‹æ‰§è¡Œæ¯æ—¥è‹±æ–‡æ–‡ç« ç”Ÿæˆä»»åŠ¡")
    print("ğŸ“‹ ç”Ÿæˆè®¡åˆ’:")
    print("   ğŸ‡ºğŸ‡¸ è‹±è¯­: 10ç¯‡")
    print("=" * 60)

    # ç”Ÿæˆè‹±æ–‡æ–‡ç«  (10ç¯‡)
    print("\nğŸ‡ºğŸ‡¸ å¼€å§‹è‹±æ–‡å…³é”®è¯é©±åŠ¨ç”Ÿæˆ...")
    english_results = generate_keyword_driven_articles("English", "en", 10)

    print(f"\nğŸ‰ æ¯æ—¥è‹±æ–‡æ–‡ç« ç”Ÿæˆä»»åŠ¡å®Œæˆ!")
    print("=" * 60)
    print(f"ğŸ“Š ç»Ÿè®¡ç»“æœ:")
    print(f"   ğŸ‡ºğŸ‡¸ è‹±æ–‡: æˆåŠŸ {english_results['success']} ç¯‡ï¼Œå¤±è´¥ {english_results['failure']} ç¯‡")

    # è®°å½•ä»»åŠ¡æ‰§è¡Œæ—¥å¿—åˆ°æ•°æ®åº“
    try:
        log_data = {
            "execution_date": datetime.now().date().isoformat(),
            "english_success": english_results["success"],
            "english_failure": english_results["failure"],
            "hindi_success": 0,
            "hindi_failure": 0,
            "bengali_success": 0,
            "bengali_failure": 0,
            "indonesian_success": 0,
            "indonesian_failure": 0,
            "total_success": english_results["success"],
            "total_failure": english_results["failure"],
            "generation_method": "keyword_driven_english_only",
            "created_at": datetime.now().isoformat()
        }
        supabase.table("auto_generation_logs").insert(log_data).execute()
        print(f"âœ… æ‰§è¡Œæ—¥å¿—å·²è®°å½•åˆ°æ•°æ®åº“")
    except Exception as log_error:
        print(f"âš ï¸ æ—¥å¿—è®°å½•å¤±è´¥ï¼ˆä¸å½±å“ä¸»è¦åŠŸèƒ½ï¼‰: {log_error}")

    return english_results

if __name__ == "__main__":
    import sys

    # æ”¯æŒå‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        command = sys.argv[1].lower()

        if command == "keywords":
            # å…³é”®è¯é©±åŠ¨æ¨¡å¼
            language = sys.argv[2] if len(sys.argv) > 2 else "all"
            count = int(sys.argv[3]) if len(sys.argv) > 3 else None

            print("ğŸš€ å¯åŠ¨å…³é”®è¯é©±åŠ¨æ–‡ç« ç”Ÿæˆæ¨¡å¼")
            print(f"ğŸŒ ç›®æ ‡è¯­è¨€: {language}")
            if count:
                print(f"ğŸ“Š ç›®æ ‡æ•°é‡: {count}ç¯‡")

            if language.lower() in ["chinese", "zh", "ä¸­æ–‡"]:
                target_count = count or 5
                print(f"\nğŸ‡¨ğŸ‡³ ä»…ç”Ÿæˆä¸­æ–‡å†…å®¹({target_count}ç¯‡)...")
                result = generate_keyword_driven_articles("Chinese (Simplified)", "zh", target_count)
                print(f"âœ… ä¸­æ–‡ç”Ÿæˆå®Œæˆ: æˆåŠŸ {result['success']} ç¯‡")
            elif language.lower() in ["english", "en", "è‹±æ–‡"]:
                target_count = count or 10  # é»˜è®¤æ”¹ä¸º10ç¯‡
                print(f"\nğŸ‡ºğŸ‡¸ ä»…ç”Ÿæˆè‹±æ–‡å†…å®¹({target_count}ç¯‡)...")
                result = generate_keyword_driven_articles("English", "en", target_count)
                print(f"âœ… è‹±æ–‡ç”Ÿæˆå®Œæˆ: æˆåŠŸ {result['success']} ç¯‡")
            elif language.lower() in ["hindi", "hi", "à¤¹à¤¿à¤‚à¤¦à¥€"]:
                target_count = count or 8
                print(f"\nğŸ‡®ğŸ‡³ ä»…ç”Ÿæˆå°åœ°è¯­å†…å®¹({target_count}ç¯‡)...")
                result = generate_keyword_driven_articles("Hindi", "hi", target_count)
                print(f"âœ… å°åœ°è¯­ç”Ÿæˆå®Œæˆ: æˆåŠŸ {result['success']} ç¯‡")
            elif language.lower() in ["urdu", "ur", "bn", "Ø§Ø±Ø¯Ùˆ"]:
                target_count = count or 3
                print(f"\nğŸ‡µğŸ‡° ä»…ç”Ÿæˆä¹Œå°”éƒ½è¯­å†…å®¹({target_count}ç¯‡)...")
                result = generate_keyword_driven_articles("Urdu", "bn", target_count)
                print(f"âœ… ä¹Œå°”éƒ½è¯­ç”Ÿæˆå®Œæˆ: æˆåŠŸ {result['success']} ç¯‡")
            elif language.lower() in ["indonesian", "id", "bahasa"]:
                target_count = count or 3
                print(f"\nğŸ‡®ğŸ‡© ä»…ç”Ÿæˆå°å°¼è¯­å†…å®¹({target_count}ç¯‡)...")
                result = generate_keyword_driven_articles("Indonesian", "id", target_count)
                print(f"âœ… å°å°¼è¯­ç”Ÿæˆå®Œæˆ: æˆåŠŸ {result['success']} ç¯‡")
            else:
                # é»˜è®¤åªç”Ÿæˆè‹±æ–‡
                target_count = count or 10
                print(f"\nğŸ‡ºğŸ‡¸ é»˜è®¤ç”Ÿæˆè‹±æ–‡å†…å®¹({target_count}ç¯‡)...")
                result = generate_keyword_driven_articles("English", "en", target_count)
                print(f"âœ… è‹±æ–‡ç”Ÿæˆå®Œæˆ: æˆåŠŸ {result['success']} ç¯‡")
        else:
            print(f"âŒ æœªçŸ¥å‘½ä»¤: {command}")
            print("ğŸ’¡ å¯ç”¨å‘½ä»¤:")
            print("   python auto_generate_articles.py keywords [language] [count]")
            print("   language å¯é€‰å€¼:")
            print("     - english/en/è‹±æ–‡ (é»˜è®¤10ç¯‡)")
            print("     - hindi/hi/à¤¹à¤¿à¤‚à¤¦à¥€ (é»˜è®¤8ç¯‡)")
            print("     - urdu/ur/bn/Ø§Ø±Ø¯Ùˆ (é»˜è®¤3ç¯‡)")
            print("     - indonesian/id/bahasa (é»˜è®¤3ç¯‡)")
            print("     - chinese/zh/ä¸­æ–‡ (é»˜è®¤5ç¯‡)")
            print("   count: å¯é€‰ï¼ŒæŒ‡å®šç”Ÿæˆæ–‡ç« æ•°é‡")
            print("   ç¤ºä¾‹:")
            print("     python auto_generate_articles.py keywords english 10")
            print("     python auto_generate_articles.py keywords english 15")
    else:
        # é»˜è®¤æ‰§è¡Œå…³é”®è¯é©±åŠ¨çš„è‹±æ–‡ç”Ÿæˆ
        main()